{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe2ec573",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU, Dropout, BatchNormalization, Conv1D, MaxPooling1D, Flatten, Input, Reshape, Conv2D, ReLU, MaxPool2D, Masking\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import ast\n",
    "from tcn import TCN\n",
    "\n",
    "# Load and preprocess the data\n",
    "# Replace 'train.csv' with the actual path to your dataset\n",
    "data = pd.read_csv('dataset/train.csv', header = None, converters = {\n",
    "    3: ast.literal_eval,\n",
    "    4: ast.literal_eval,\n",
    "    5: ast.literal_eval\n",
    "}, skiprows = 1)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['acc_x'] = data[3]\n",
    "df['acc_y'] = data[4]\n",
    "df['acc_z'] = data[5]\n",
    "df['gesture'] = data[2]\n",
    "\n",
    "#remove invalid rows\n",
    "df.drop(df.loc[df['acc_x']==0].index, inplace=True)\n",
    "df.drop(df.loc[df['acc_y']==0].index, inplace=True)\n",
    "df.drop(df.loc[df['acc_z']==0].index, inplace=True)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert the lists into arrays\n",
    "acc_x = df['acc_x'].values\n",
    "acc_y = df['acc_y'].values\n",
    "acc_z = df['acc_z'].values\n",
    "\n",
    "# Combine all axes into a sequence of shape (timesteps, features)\n",
    "sequences = [np.array([x, y, z]).T for x, y, z in zip(acc_x, acc_y, acc_z)]\n",
    "\n",
    "# Pad sequences to the length of the longest sequence\n",
    "padded_sequences = pad_sequences(sequences, maxlen = 32, padding='post', dtype='float32')\n",
    "\n",
    "# Encode labels\n",
    "labels = df['gesture'].values\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "categorical_labels = to_categorical(encoded_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebaa9684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA AUGMENTATION preprocessing\n",
    "\n",
    "#adding noise\n",
    "def add_noise(data, noise_level=0.05):\n",
    "    return (data + np.random.normal(0, noise_level, data.shape)).astype(np.float32)\n",
    "\n",
    "# Original data: `x_train` (accelerometer sequences), `y_train` (labels)\n",
    "\n",
    "padded_sequences = np.concatenate((padded_sequences, add_noise(padded_sequences)))\n",
    "categorical_labels = np.concatenate((categorical_labels, categorical_labels))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def scale_data(data, scaling_factor=0.1):\n",
    "    \"\"\"\n",
    "    Scale the data by a random factor.\n",
    "    Args:\n",
    "        data: Numpy array of shape (time_steps, 3).\n",
    "        scaling_factor: Max scaling factor variation.\n",
    "    Returns:\n",
    "        Scaled data.\n",
    "    \"\"\"\n",
    "    factor = 1 + np.random.uniform(-scaling_factor, scaling_factor)\n",
    "    return (data * factor).astype(np.float32)\n",
    "\n",
    "padded_sequences = np.concatenate((padded_sequences, scale_data(padded_sequences)))\n",
    "categorical_labels = np.concatenate((categorical_labels, categorical_labels))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c22ed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "    padded_sequences, categorical_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train, y_train, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81763a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_13 (Conv1D)          (None, 32, 18)            180       \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 32, 18)            0         \n",
      "                                                                 \n",
      " batch_normalization_39 (Ba  (None, 32, 18)            72        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_39 (ReLU)             (None, 32, 18)            0         \n",
      "                                                                 \n",
      " reshape_13 (Reshape)        (None, 16, 12, 3)         0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 16, 12, 8)         224       \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 16, 12, 8)         0         \n",
      "                                                                 \n",
      " batch_normalization_40 (Ba  (None, 16, 12, 8)         32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_40 (ReLU)             (None, 16, 12, 8)         0         \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPooli  (None, 8, 6, 8)           0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 18)                6930      \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 18)                0         \n",
      "                                                                 \n",
      " batch_normalization_41 (Ba  (None, 18)                72        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_41 (ReLU)             (None, 18)                0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 20)                380       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7890 (30.82 KB)\n",
      "Trainable params: 7802 (30.48 KB)\n",
      "Non-trainable params: 88 (352.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "214/214 [==============================] - 2s 6ms/step - loss: 2.7994 - accuracy: 0.1358 - val_loss: 2.5205 - val_accuracy: 0.4737\n",
      "Epoch 2/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 2.2778 - accuracy: 0.2993 - val_loss: 2.1392 - val_accuracy: 0.6482\n",
      "Epoch 3/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 1.9423 - accuracy: 0.3974 - val_loss: 1.7907 - val_accuracy: 0.7298\n",
      "Epoch 4/50\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 1.6862 - accuracy: 0.4646 - val_loss: 1.4569 - val_accuracy: 0.8136\n",
      "Epoch 5/50\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 1.5215 - accuracy: 0.5126 - val_loss: 1.0734 - val_accuracy: 0.8570\n",
      "Epoch 6/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 1.3800 - accuracy: 0.5569 - val_loss: 0.9015 - val_accuracy: 0.8596\n",
      "Epoch 7/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 1.2681 - accuracy: 0.5901 - val_loss: 0.7344 - val_accuracy: 0.8794\n",
      "Epoch 8/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 1.1939 - accuracy: 0.6120 - val_loss: 0.6584 - val_accuracy: 0.8956\n",
      "Epoch 9/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 1.1277 - accuracy: 0.6313 - val_loss: 0.5884 - val_accuracy: 0.8860\n",
      "Epoch 10/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 1.0649 - accuracy: 0.6488 - val_loss: 0.5137 - val_accuracy: 0.9022\n",
      "Epoch 11/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 1.0273 - accuracy: 0.6560 - val_loss: 0.4745 - val_accuracy: 0.8947\n",
      "Epoch 12/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 0.9999 - accuracy: 0.6589 - val_loss: 0.4600 - val_accuracy: 0.9009\n",
      "Epoch 13/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 0.9676 - accuracy: 0.6725 - val_loss: 0.4206 - val_accuracy: 0.9171\n",
      "Epoch 14/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 0.9305 - accuracy: 0.6947 - val_loss: 0.3927 - val_accuracy: 0.9294\n",
      "Epoch 15/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 0.9084 - accuracy: 0.7006 - val_loss: 0.3711 - val_accuracy: 0.9228\n",
      "Epoch 16/50\n",
      "214/214 [==============================] - 1s 6ms/step - loss: 0.8812 - accuracy: 0.7007 - val_loss: 0.3416 - val_accuracy: 0.9368\n",
      "Epoch 17/50\n",
      "214/214 [==============================] - 1s 7ms/step - loss: 0.8715 - accuracy: 0.7039 - val_loss: 0.3381 - val_accuracy: 0.9338\n",
      "Epoch 18/50\n",
      "214/214 [==============================] - 1s 6ms/step - loss: 0.8623 - accuracy: 0.7082 - val_loss: 0.3273 - val_accuracy: 0.9285\n",
      "Epoch 19/50\n",
      "214/214 [==============================] - 1s 6ms/step - loss: 0.8280 - accuracy: 0.7208 - val_loss: 0.2972 - val_accuracy: 0.9496\n",
      "Epoch 20/50\n",
      "214/214 [==============================] - 1s 6ms/step - loss: 0.8166 - accuracy: 0.7262 - val_loss: 0.2996 - val_accuracy: 0.9417\n",
      "Epoch 21/50\n",
      "214/214 [==============================] - 1s 6ms/step - loss: 0.7900 - accuracy: 0.7298 - val_loss: 0.2819 - val_accuracy: 0.9447\n",
      "Epoch 22/50\n",
      "214/214 [==============================] - 1s 6ms/step - loss: 0.7839 - accuracy: 0.7272 - val_loss: 0.2728 - val_accuracy: 0.9439\n",
      "Epoch 23/50\n",
      "214/214 [==============================] - 1s 6ms/step - loss: 0.7740 - accuracy: 0.7417 - val_loss: 0.2771 - val_accuracy: 0.9452\n",
      "Epoch 24/50\n",
      "214/214 [==============================] - 1s 6ms/step - loss: 0.7490 - accuracy: 0.7501 - val_loss: 0.2512 - val_accuracy: 0.9509\n",
      "Epoch 25/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 0.7484 - accuracy: 0.7404 - val_loss: 0.2368 - val_accuracy: 0.9579\n",
      "Epoch 26/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 0.7428 - accuracy: 0.7458 - val_loss: 0.2272 - val_accuracy: 0.9575\n",
      "Epoch 27/50\n",
      "214/214 [==============================] - 1s 7ms/step - loss: 0.7336 - accuracy: 0.7480 - val_loss: 0.2378 - val_accuracy: 0.9561\n",
      "Epoch 28/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 0.7225 - accuracy: 0.7545 - val_loss: 0.2141 - val_accuracy: 0.9592\n",
      "Epoch 29/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 0.7126 - accuracy: 0.7500 - val_loss: 0.2067 - val_accuracy: 0.9592\n",
      "Epoch 30/50\n",
      "214/214 [==============================] - 1s 6ms/step - loss: 0.7163 - accuracy: 0.7529 - val_loss: 0.2124 - val_accuracy: 0.9596\n",
      "Epoch 31/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 0.7079 - accuracy: 0.7573 - val_loss: 0.2140 - val_accuracy: 0.9583\n",
      "Epoch 32/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 0.6984 - accuracy: 0.7640 - val_loss: 0.2023 - val_accuracy: 0.9636\n",
      "Epoch 33/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 0.6994 - accuracy: 0.7652 - val_loss: 0.1926 - val_accuracy: 0.9618\n",
      "Epoch 34/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 0.6728 - accuracy: 0.7721 - val_loss: 0.1864 - val_accuracy: 0.9588\n",
      "Epoch 35/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 0.6816 - accuracy: 0.7690 - val_loss: 0.1855 - val_accuracy: 0.9618\n",
      "Epoch 36/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 0.6674 - accuracy: 0.7735 - val_loss: 0.1780 - val_accuracy: 0.9636\n",
      "Epoch 37/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 0.6475 - accuracy: 0.7814 - val_loss: 0.1872 - val_accuracy: 0.9605\n",
      "Epoch 38/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 0.6748 - accuracy: 0.7673 - val_loss: 0.1888 - val_accuracy: 0.9601\n",
      "Epoch 39/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 0.6452 - accuracy: 0.7858 - val_loss: 0.1775 - val_accuracy: 0.9640\n",
      "Epoch 40/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 0.6375 - accuracy: 0.7858 - val_loss: 0.1672 - val_accuracy: 0.9601\n",
      "Epoch 41/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 0.6230 - accuracy: 0.7860 - val_loss: 0.1671 - val_accuracy: 0.9614\n",
      "Epoch 42/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 0.6394 - accuracy: 0.7785 - val_loss: 0.1746 - val_accuracy: 0.9592\n",
      "Epoch 43/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 0.6287 - accuracy: 0.7883 - val_loss: 0.1598 - val_accuracy: 0.9684\n",
      "Epoch 44/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 0.6311 - accuracy: 0.7803 - val_loss: 0.1647 - val_accuracy: 0.9654\n",
      "Epoch 45/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 0.6280 - accuracy: 0.7849 - val_loss: 0.1632 - val_accuracy: 0.9636\n",
      "Epoch 46/50\n",
      "214/214 [==============================] - 1s 6ms/step - loss: 0.6270 - accuracy: 0.7879 - val_loss: 0.1515 - val_accuracy: 0.9711\n",
      "Epoch 47/50\n",
      "214/214 [==============================] - 1s 6ms/step - loss: 0.6027 - accuracy: 0.7927 - val_loss: 0.1545 - val_accuracy: 0.9689\n",
      "Epoch 48/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 0.6212 - accuracy: 0.7860 - val_loss: 0.1529 - val_accuracy: 0.9636\n",
      "Epoch 49/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 0.6001 - accuracy: 0.7914 - val_loss: 0.1508 - val_accuracy: 0.9684\n",
      "Epoch 50/50\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 0.6115 - accuracy: 0.7925 - val_loss: 0.1642 - val_accuracy: 0.9592\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1439 - accuracy: 0.9675\n",
      "Test Loss: 0.14392052590847015, Test Accuracy: 0.9675438404083252\n",
      " 1/72 [..............................] - ETA: 7s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amroset/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Neural network model\n",
    "model = Sequential([\n",
    "   Input(shape=(32, 3)),\n",
    "    # Mask padding values\n",
    "    #Masking(mask_value=0.0, input_shape=(None, 3)),\n",
    "    Conv1D(filters=18, kernel_size = 3, padding = \"causal\"),\n",
    "    Dropout(0.3),\n",
    "    BatchNormalization(),\n",
    "    ReLU(),\n",
    "    Reshape((16,12,3)),\n",
    "    Conv2D(filters=8, kernel_size = (3,3), padding= \"same\"),\n",
    "    Dropout(0.4),\n",
    "    BatchNormalization(),\n",
    "    ReLU(),\n",
    "    MaxPool2D(pool_size = 2),\n",
    "    \n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(18),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    ReLU(),\n",
    "\n",
    "    Dense(len(label_encoder.classes_), activation = 'softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_validation, y_validation),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Save the model\n",
    "model.save('models/tcn_gesture_classification_model.h5')\n",
    "\n",
    "# Decode predicted labels for interpretability\n",
    "predicted_classes = label_encoder.inverse_transform(np.argmax(model.predict(X_test), axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d25fb062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 4ms/step\n",
      "Predictions saved to test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "#Inference\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('models/tcn_gesture_classification_model.h5')\n",
    "#Save model graph for TensorBoard visualization\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv('dataset/test.csv', header=None, converters={\n",
    "    2: ast.literal_eval,\n",
    "    3: ast.literal_eval,\n",
    "    4: ast.literal_eval\n",
    "}, skiprows=1)\n",
    "\n",
    "# Preprocess the test data\n",
    "df_test = pd.DataFrame()\n",
    "df_test['acc_x'] = test_data[2]\n",
    "df_test['acc_y'] = test_data[3]\n",
    "df_test['acc_z'] = test_data[4]\n",
    "\n",
    "# Ensure all data is consistent (dropping invalid or zero entries)\n",
    "df_test.drop(df_test.loc[df_test['acc_x'] == 0].index, inplace=True)\n",
    "df_test.drop(df_test.loc[df_test['acc_y'] == 0].index, inplace=True)\n",
    "df_test.drop(df_test.loc[df_test['acc_z'] == 0].index, inplace=True)\n",
    "\n",
    "df_test = df_test.dropna()\n",
    "\n",
    "# Extract accelerometer data (acc_x, acc_y, acc_z) for the test set\n",
    "acc_x = df_test['acc_x'].values\n",
    "acc_y = df_test['acc_y'].values\n",
    "acc_z = df_test['acc_z'].values\n",
    "\n",
    "test_sequences = [np.array([x, y, z]).T for x, y, z in zip(acc_x, acc_y, acc_z)]\n",
    "\n",
    "# Pad sequences to the length of the longest sequence\n",
    "padded_test_sequences = pad_sequences(test_sequences, padding='post', dtype='float32')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(padded_test_sequences)\n",
    "\n",
    "# Decode predictions to gesture classes\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# If you used a LabelEncoder for training, decode the classes\n",
    "# Replace 'label_encoder' with your encoder used during training\n",
    "gesture_labels = label_encoder.inverse_transform(predicted_classes)\n",
    "\n",
    "df_out = pd.DataFrame()\n",
    "df_out['id'] = test_data[0]\n",
    "df_out['gesture'] = gesture_labels\n",
    "\n",
    "\n",
    "# Save the results\n",
    "df_out.to_csv('cnn_test_predictions.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to test_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d07945f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphinzwzht/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphinzwzht/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with full integer quantization saved as gesture_classification_model_integer.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amroset/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2025-01-04 13:24:43.282900: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2025-01-04 13:24:43.282923: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2025-01-04 13:24:43.283161: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmphinzwzht\n",
      "2025-01-04 13:24:43.284951: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-01-04 13:24:43.284969: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmphinzwzht\n",
      "2025-01-04 13:24:43.289216: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2025-01-04 13:24:43.290448: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2025-01-04 13:24:43.342223: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmphinzwzht\n",
      "2025-01-04 13:24:43.355091: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 71927 microseconds.\n",
      "2025-01-04 13:24:43.382183: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 17, Total Ops 34, % non-converted = 50.00 %\n",
      " * 17 ARITH ops\n",
      "\n",
      "- arith.constant:   17 occurrences  (f32: 8, i32: 9)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (i32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 3)\n",
      "  (i32: 1)\n",
      "  (f32: 1)\n",
      "  (i32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(padded_sequences).batch(1).take(32):\n",
    "    yield [input_value]\n",
    "\n",
    "# Ensure input shape is fixed\n",
    "model.build(input_shape=(None, 32, 3))  # Example: Fixed length 32 timesteps, 3 features\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# Apply integer quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]  # Ensure compatibility\n",
    "converter.inference_input_type = tf.uint8  # Optional: Set input type\n",
    "converter.inference_output_type = tf.uint8  # Optional: Set output type\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model\n",
    "with open('models/tcn_gesture_classification_model_integer.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Model with full integer quantization saved as gesture_classification_model_integer.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94fc5796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp8t3w93n_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp8t3w93n_/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDF5 Model size without quantization: 165 KB\n",
      "TFLite Model size without quantization: 36 KB\n",
      "\n",
      "Reduction in file size by a factor of 4.489317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 13:24:46.328520: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2025-01-04 13:24:46.328544: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2025-01-04 13:24:46.328667: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp8t3w93n_\n",
      "2025-01-04 13:24:46.330389: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-01-04 13:24:46.330406: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp8t3w93n_\n",
      "2025-01-04 13:24:46.334689: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2025-01-04 13:24:46.380643: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp8t3w93n_\n",
      "2025-01-04 13:24:46.393265: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 64597 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 17, Total Ops 34, % non-converted = 50.00 %\n",
      " * 17 ARITH ops\n",
      "\n",
      "- arith.constant:   17 occurrences  (f32: 8, i32: 9)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (i32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 3)\n",
      "  (i32: 1)\n",
      "  (f32: 1)\n",
      "  (i32: 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Convert the model to TFLite without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "fp_tflite_model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(\"models/tcn_model_f32.tflite\", \"wb\").write(fp_tflite_model)\n",
    "\n",
    "# Show the model size for the non-quantized HDF5 model\n",
    "fp_h5_in_kb = os.path.getsize('models/tcn_gesture_classification_model.h5') / 1024\n",
    "print(\"HDF5 Model size without quantization: %d KB\" % fp_h5_in_kb)\n",
    "\n",
    "# Show the model size for the non-quantized TFLite model\n",
    "fp_tflite_in_kb = os.path.getsize('models/tcn_model_f32.tflite') / 1024\n",
    "print(\"TFLite Model size without quantization: %d KB\" % fp_tflite_in_kb)\n",
    "\n",
    "# Determine the reduction in model size\n",
    "print(\"\\nReduction in file size by a factor of %f\" % (fp_h5_in_kb / fp_tflite_in_kb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90af0a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.uint8'>\n",
      "output:  <class 'numpy.uint8'>\n",
      "TFLite Model size with 8-bit quantization: 16 KB\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)\n",
    "\n",
    "# Show the model size for the 8-bit quantized TFLite model\n",
    "tflite_quant_in_kb = os.path.getsize('models/tcn_gesture_classification_model_integer.tflite') / 1024\n",
    "print(\"TFLite Model size with 8-bit quantization: %d KB\" % tflite_quant_in_kb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1ff3df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Helper function to run inference on a TFLite model\n",
    "\n",
    "test_sequence_indices = range(X_test.shape[0])\n",
    "\n",
    "print(y_test)\n",
    "\n",
    "def run_tflite_model(tflite_file, test_image_indices):\n",
    "  global X_test\n",
    "\n",
    "  # Initialize the interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  predictions = []\n",
    "  for i, test_sequence_index in enumerate(test_sequence_indices):\n",
    "    test_sequence = X_test[test_sequence_index]\n",
    "    test_label = y_test[test_sequence_index]\n",
    "\n",
    "    if (test_sequence_index % 100 == 0):\n",
    "      print(\"Evaluated on %d sequences.\" % test_sequence_index)\n",
    "\n",
    "    # Check if the input type is quantized, then rescale input data to uint8\n",
    "    if input_details['dtype'] == np.uint8:\n",
    "      input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "      test_sequence = test_sequence / input_scale + input_zero_point\n",
    "\n",
    "    test_sequence = np.expand_dims(test_sequence, axis=0).astype(input_details[\"dtype\"])\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_sequence)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "    predictions.append(np.argmax(output, axis=-1))\n",
    "\n",
    "  return predictions\n",
    "\n",
    "\n",
    "# Helper function to evaluate a TFLite model on all images\n",
    "def evaluate_model(tflite_file, model_type):\n",
    "  global X_test\n",
    "  global y_test\n",
    "\n",
    "  test_sequence_indices = range(X_train.shape[0])\n",
    "  predictions = run_tflite_model(tflite_file, test_sequence_indices)\n",
    "    \n",
    "  labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "  accuracy = (np.sum(labels == predictions) * 100) / len(X_test)\n",
    "\n",
    "  print('%s model accuracy is %.4f%% (Number of test samples=%d)' % (\n",
    "      model_type, accuracy, len(X_test)))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60907cd0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 sequences.\n",
      "Evaluated on 100 sequences.\n",
      "Evaluated on 200 sequences.\n",
      "Evaluated on 300 sequences.\n",
      "Evaluated on 400 sequences.\n",
      "Evaluated on 500 sequences.\n",
      "Evaluated on 600 sequences.\n",
      "Evaluated on 700 sequences.\n",
      "Evaluated on 800 sequences.\n",
      "Evaluated on 900 sequences.\n",
      "Evaluated on 1000 sequences.\n",
      "Evaluated on 1100 sequences.\n",
      "Evaluated on 1200 sequences.\n",
      "Evaluated on 1300 sequences.\n",
      "Evaluated on 1400 sequences.\n",
      "Evaluated on 1500 sequences.\n",
      "Evaluated on 1600 sequences.\n",
      "Evaluated on 1700 sequences.\n",
      "Evaluated on 1800 sequences.\n",
      "Evaluated on 1900 sequences.\n",
      "Evaluated on 2000 sequences.\n",
      "Evaluated on 2100 sequences.\n",
      "Evaluated on 2200 sequences.\n",
      "Full Post-Quantized INT8 model accuracy is 95.9211% (Number of test samples=2280)\n",
      "0.026128482073545456\n",
      "119\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "# this might take a few minutes (~ 1- 2 minutes)\n",
    "# if it takes longer than that, I suggest to \n",
    "# restart the runtime and try again\n",
    "# if the issue still persists, restart your computer\n",
    "tflite_model_quant_int8_file = pathlib.Path('models/tcn_gesture_classification_model_integer.tflite')\n",
    "tflite_model_quant_int8_model_type = \"Full Post-Quantized INT8\"\n",
    "\n",
    "evaluate_model(tflite_model_quant_int8_file, tflite_model_quant_int8_model_type)\n",
    "\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "\n",
    "print(input_scale)\n",
    "print(input_zero_point)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f5cb06e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 sequences.\n",
      "Evaluated on 100 sequences.\n",
      "Evaluated on 200 sequences.\n",
      "Evaluated on 300 sequences.\n",
      "Evaluated on 400 sequences.\n",
      "Evaluated on 500 sequences.\n",
      "Evaluated on 600 sequences.\n",
      "Evaluated on 700 sequences.\n",
      "Evaluated on 800 sequences.\n",
      "Evaluated on 900 sequences.\n",
      "Evaluated on 1000 sequences.\n",
      "Evaluated on 1100 sequences.\n",
      "Evaluated on 1200 sequences.\n",
      "Evaluated on 1300 sequences.\n",
      "Evaluated on 1400 sequences.\n",
      "Evaluated on 1500 sequences.\n",
      "Evaluated on 1600 sequences.\n",
      "Evaluated on 1700 sequences.\n",
      "Evaluated on 1800 sequences.\n",
      "Evaluated on 1900 sequences.\n",
      "Evaluated on 2000 sequences.\n",
      "Evaluated on 2100 sequences.\n",
      "Evaluated on 2200 sequences.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_test, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      9\u001b[0m full_int8_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(labels, tflite_model_quant_int8_pred)\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull-precision model accuracy is \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m (Number of test samples=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[43mtest_accuracy\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m, \u001b[38;5;28mlen\u001b[39m(y_test)))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuantized model accuracy is \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m (Number of test samples=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (full_int8_accuracy \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m, \u001b[38;5;28mlen\u001b[39m(y_test)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "# we plot also the confusion matrix of the quantized model\n",
    "tflite_model_quant_int8_pred = run_tflite_model(tflite_model_quant_int8_file, range(y_test.shape[0]))\n",
    "\n",
    "# compute the accuracy of the quantized model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "full_int8_accuracy = accuracy_score(labels, tflite_model_quant_int8_pred)\n",
    "print(\"Full-precision model accuracy is %.4f%% (Number of test samples=%d)\" % (test_accuracy * 100, len(y_test)))\n",
    "print(\"Quantized model accuracy is %.4f%% (Number of test samples=%d)\" % (full_int8_accuracy * 100, len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02a86b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Convert some hex value into an array for C programming\n",
    "def hex_to_c_array(hex_data, var_name):\n",
    "\n",
    "    c_str = ''\n",
    "\n",
    "    # Create header guard\n",
    "    c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n",
    "    c_str += '#define ' + var_name.upper() + '_H\\n\\n'\n",
    "\n",
    "    # Add array length at top of file\n",
    "    c_str += '\\nstatic const unsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n",
    "\n",
    "    # Declare C variable\n",
    "    c_str += 'static const unsigned char ' + var_name + '[] = {'\n",
    "    hex_array = []\n",
    "    for i, val in enumerate(hex_data) :\n",
    "\n",
    "        # Construct string from hex\n",
    "        hex_str = format(val, '#04x')\n",
    "\n",
    "        # Add formatting so each line stays within 80 characters\n",
    "        if (i + 1) < len(hex_data):\n",
    "            hex_str += ','\n",
    "        if (i + 1) % 12 == 0:\n",
    "            hex_str += '\\n '\n",
    "        hex_array.append(hex_str)\n",
    "\n",
    "    # Add closing brace\n",
    "    c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n",
    "\n",
    "    # Close out header guard\n",
    "    c_str += '#endif //' + var_name.upper() + '_H'\n",
    "\n",
    "    return c_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0392b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_model_name = 'q8_tcn'\n",
    "# check if dir 'cfiles' exists, if not create it\n",
    "if not os.path.exists('cfiles'):\n",
    "    os.makedirs('cfiles')\n",
    "# Write TFLite model to a C source (or header) file\n",
    "with open('cfiles/' + c_model_name + '.h', 'w') as file:\n",
    "    file.write(hex_to_c_array(tflite_model, c_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4445fc11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image data location:  /home/amroset/Machine Learning on Microcontrollers/Project/x_test_gestures.npy\n",
      "Test labels location:  /home/amroset/Machine Learning on Microcontrollers/Project/y_test_gestures.npy\n"
     ]
    }
   ],
   "source": [
    "input_details = interpreter.get_input_details()[0]\n",
    "input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "\n",
    "# save the test data as numpy arrays\n",
    "np.save('x_test_gestures.npy', (X_test / input_scale + input_zero_point).astype(np.uint8))\n",
    "np.save('y_test_gestures.npy', (y_test.astype(np.uint8)))\n",
    "\n",
    "# print the location of the files\n",
    "print('Test image data location: ', os.path.abspath('x_test_gestures.npy'))\n",
    "print('Test labels location: ', os.path.abspath('y_test_gestures.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d53c758a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tflite_model_quant_int8_qat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m interpreter \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlite\u001b[38;5;241m.\u001b[39mInterpreter(model_content\u001b[38;5;241m=\u001b[39m\u001b[43mtflite_model_quant_int8_qat\u001b[49m)\n\u001b[1;32m      2\u001b[0m input_type \u001b[38;5;241m=\u001b[39m interpreter\u001b[38;5;241m.\u001b[39mget_input_details()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;124m'\u001b[39m, input_type)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tflite_model_quant_int8_qat' is not defined"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant_int8_qat)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)\n",
    "# Save the quantized model to disk\n",
    "open(\"models/gesture_qat_int8.tflite\", \"wb\").write(tflite_model_quant_int8_qat)\n",
    "\n",
    "# Show the model size for the 8-bit quantized TFLite model\n",
    "tflite_quant_in_kb = os.path.getsize('models/gesture_qat_int8.tflite') / 1024\n",
    "print(\"TFLite Model size with 8-bit quantization: %d KB\" % tflite_quant_in_kb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "693a76de",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_model_name = 'qat8_gesture'\n",
    "# Write TFLite model to a C source (or header) file\n",
    "with open(c_model_name + '.h', 'w') as file:\n",
    "    file.write(hex_to_c_array(tflite_model_quant_int8_qat, c_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "348ac827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 sequences.\n",
      "Evaluated on 100 sequences.\n",
      "Evaluated on 200 sequences.\n",
      "Evaluated on 300 sequences.\n",
      "Evaluated on 400 sequences.\n",
      "Evaluated on 500 sequences.\n",
      "Evaluated on 600 sequences.\n",
      "Evaluated on 700 sequences.\n",
      "Evaluated on 800 sequences.\n",
      "Evaluated on 900 sequences.\n",
      "Evaluated on 1000 sequences.\n",
      "Evaluated on 1100 sequences.\n",
      "Evaluated on 1200 sequences.\n",
      "Evaluated on 1300 sequences.\n",
      "Evaluated on 1400 sequences.\n",
      "Evaluated on 1500 sequences.\n",
      "Evaluated on 1600 sequences.\n",
      "Evaluated on 1700 sequences.\n",
      "Evaluated on 1800 sequences.\n",
      "Evaluated on 1900 sequences.\n",
      "Evaluated on 2000 sequences.\n",
      "Evaluated on 2100 sequences.\n",
      "Evaluated on 2200 sequences.\n",
      "Full QAT INT8 model accuracy is 97.8070% (Number of test samples=2280)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m tflite_model_quant_int8_qat_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull QAT INT8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m evaluate_model(tflite_model_quant_int8_qat_file, tflite_model_quant_int8_qat_type)\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull-precision model accuracy is \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m (Number of test samples=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[43mtest_accuracy\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m, \u001b[38;5;28mlen\u001b[39m(X_train)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "# this might take a few minutes (~ 1- 2 minutes)\n",
    "# if it takes longer than that, I suggest to \n",
    "# restart the runtime and try again\n",
    "# if the issue still persists, restart your computer\n",
    "tflite_model_quant_int8_qat_file = pathlib.Path('models/gesture_tcn_qat_int8.tflite')\n",
    "tflite_model_quant_int8_qat_type = \"Full QAT INT8\"\n",
    "\n",
    "evaluate_model(tflite_model_quant_int8_qat_file, tflite_model_quant_int8_qat_type)\n",
    "print(\"Full-precision model accuracy is %.4f%% (Number of test samples=%d)\" % (test_accuracy * 100, len(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09faa18b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_tflite_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m tflite_model_quant_int8_qat_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/gesture_qat_int8.tflite\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m tflite_model_quant_int8_qat_model_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuantized aware training model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m tflite_model_quant_int8_qat_pred \u001b[38;5;241m=\u001b[39m \u001b[43mrun_tflite_model\u001b[49m(tflite_model_quant_int8_qat_file, \u001b[38;5;28mrange\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'run_tflite_model' is not defined"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the test set\n",
    "tflite_model_quant_int8_qat_file = \"models/gesture_qat_int8.tflite\"\n",
    "tflite_model_quant_int8_qat_model_type = \"Quantized aware training model\"\n",
    "tflite_model_quant_int8_qat_pred = run_tflite_model(tflite_model_quant_int8_qat_file, range(X_train.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "715b57f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full QAT INT8 accuracy is 99.3860% (Number of test samples=2280)\n",
      "Full-precision model accuracy is 97.0614% (Number of test samples=2280)\n"
     ]
    }
   ],
   "source": [
    "# compute the accuracy of the model\n",
    "full_qat_int8_accuracy = accuracy_score(labels, tflite_model_quant_int8_qat_pred)\n",
    "print('Full QAT INT8 accuracy is %.4f%% (Number of test samples=%d)' % (full_qat_int8_accuracy * 100, len(y_test)))\n",
    "print('Full-precision model accuracy is %.4f%% (Number of test samples=%d)' % (test_accuracy * 100, len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afe9b8f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`prune_low_magnitude` can only prune an object of the following types: keras.models.Sequential, keras functional model, keras.layers.Layer, list of keras.layers.Layer. You passed an object of type: Sequential.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 15\u001b[0m\n\u001b[1;32m     10\u001b[0m pruning_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpruning_schedule\u001b[39m\u001b[38;5;124m'\u001b[39m: tfmot\u001b[38;5;241m.\u001b[39msparsity\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mConstantSparsity(\u001b[38;5;241m0.2\u001b[39m, begin_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, frequency\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m),\n\u001b[1;32m     12\u001b[0m }\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Create a pruning model\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m pruned_model_unstructured \u001b[38;5;241m=\u001b[39m \u001b[43mtfmot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparsity\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprune_low_magnitude\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpruning_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# `prune_low_magnitude` requires a recompile.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m pruned_model_unstructured\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     19\u001b[0m                 loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m                 metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/keras/metrics.py:74\u001b[0m, in \u001b[0;36mMonitorBoolGauge.__call__.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m     73\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbool_gauge\u001b[38;5;241m.\u001b[39mget_cell(MonitorBoolGauge\u001b[38;5;241m.\u001b[39m_FAILURE_LABEL)\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 74\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "File \u001b[0;32m~/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/keras/metrics.py:69\u001b[0m, in \u001b[0;36mMonitorBoolGauge.__call__.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     68\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbool_gauge\u001b[38;5;241m.\u001b[39mget_cell(MonitorBoolGauge\u001b[38;5;241m.\u001b[39m_SUCCESS_LABEL)\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/prune.py:216\u001b[0m, in \u001b[0;36mprune_low_magnitude\u001b[0;34m(to_prune, pruning_schedule, block_size, block_pooling_type, pruning_policy, sparsity_m_by_n, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m pruning_wrapper\u001b[38;5;241m.\u001b[39mPruneLowMagnitude(to_prune, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 216\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    217\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`prune_low_magnitude` can only prune an object of the following \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    218\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtypes: keras.models.Sequential, keras functional model, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    219\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras.layers.Layer, list of keras.layers.Layer. You passed \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    220\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124man object of type: \u001b[39m\u001b[38;5;132;01m{input}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mto_prune\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    221\u001b[0m   )\n",
      "\u001b[0;31mValueError\u001b[0m: `prune_low_magnitude` can only prune an object of the following types: keras.models.Sequential, keras functional model, keras.layers.Layer, list of keras.layers.Layer. You passed an object of type: Sequential."
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('models/tcn_gesture_classification_model.h5')\n",
    "\n",
    "\n",
    "# Unstrucutred pruning with constant sparsity\n",
    "pruning_params = {\n",
    "        'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(0.2, begin_step=200, frequency=50),\n",
    "}\n",
    "\n",
    "# Create a pruning model\n",
    "pruned_model_unstructured = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "pruned_model_unstructured.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "pruned_model_unstructured.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5165ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 0.7426 - accuracy: 0.7417 - val_loss: 0.1312 - val_accuracy: 0.9772 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.7242 - accuracy: 0.7532 - val_loss: 0.1332 - val_accuracy: 0.9715 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.7074 - accuracy: 0.7610 - val_loss: 0.1365 - val_accuracy: 0.9737 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "205/214 [===========================>..] - ETA: 0s - loss: 0.7014 - accuracy: 0.7593\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.7017 - accuracy: 0.7595 - val_loss: 0.1346 - val_accuracy: 0.9732 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.6793 - accuracy: 0.7687 - val_loss: 0.1204 - val_accuracy: 0.9785 - lr: 5.0000e-04\n",
      "Epoch 6/10\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.6921 - accuracy: 0.7645 - val_loss: 0.1243 - val_accuracy: 0.9776 - lr: 5.0000e-04\n",
      "Epoch 7/10\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.6681 - accuracy: 0.7673 - val_loss: 0.1209 - val_accuracy: 0.9768 - lr: 5.0000e-04\n",
      "Epoch 8/10\n",
      "198/214 [==========================>...] - ETA: 0s - loss: 0.6663 - accuracy: 0.7760\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.6690 - accuracy: 0.7746 - val_loss: 0.1206 - val_accuracy: 0.9798 - lr: 5.0000e-04\n",
      "Epoch 9/10\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.6744 - accuracy: 0.7665 - val_loss: 0.1181 - val_accuracy: 0.9781 - lr: 2.5000e-04\n",
      "Epoch 10/10\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.6813 - accuracy: 0.7617 - val_loss: 0.1160 - val_accuracy: 0.9811 - lr: 2.5000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x754a0417cfd0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate the pruned model\n",
    "\n",
    "pruned_model_unstructured.fit(\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    epochs=10,\n",
    "                    validation_data=(X_validation, y_validation),\n",
    "                    callbacks = [es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "936ec194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned model loss:  0.09222695231437683\n",
      "Pruned model accuracy:  0.9881578683853149\n",
      "Full-precision model accuracy:  0.9706140160560608\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the test set\n",
    "pruned_loss_unstructured, pruned_acc_unstructured = pruned_model_unstructured.evaluate(X_test, y_test, verbose=0)\n",
    "print('Pruned model loss: ', pruned_loss_unstructured)\n",
    "print('Pruned model accuracy: ', pruned_acc_unstructured)\n",
    "print('Full-precision model accuracy: ', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f9d0d144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56514/499473255.py:4: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(pruned_model_unstructured_for_export, pruned_keras_file_unstructured, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "pruned_model_unstructured_for_export = tfmot.sparsity.keras.strip_pruning(pruned_model_unstructured)\n",
    "\n",
    "pruned_keras_file_unstructured = 'models/pruned_model_unstructured.h5'\n",
    "tf.keras.models.save_model(pruned_model_unstructured_for_export, pruned_keras_file_unstructured, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e8660a71",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to clone model. This generally happens if you used custom Keras layers or objects in your model. Please specify them via `quantize_scope` for your calls to `quantize_model` and `quantize_apply`. [Layer <tf_keras.src.layers.reshaping.reshape.Reshape object at 0x7a5d7df5a1a0> supplied to wrapper is not a supported layer type. Please ensure wrapped layer is a valid Keras layer.].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/keras/src/layers/rnn/base_wrapper.py:45\u001b[0m, in \u001b[0;36mWrapper.__init__\u001b[0;34m(self, layer, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, Layer)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[0;31mAssertionError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py:460\u001b[0m, in \u001b[0;36mquantize_apply\u001b[0;34m(model, scheme, quantized_layer_name_prefix)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 460\u001b[0m   model_copy \u001b[38;5;241m=\u001b[39m \u001b[43m_clone_model_with_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m er:\n",
      "File \u001b[0;32m~/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py:369\u001b[0m, in \u001b[0;36mquantize_apply.<locals>._clone_model_with_weights\u001b[0;34m(model_to_clone)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_clone_model_with_weights\u001b[39m(model_to_clone):\n\u001b[0;32m--> 369\u001b[0m   cloned_model \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_to_clone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m   cloned_model\u001b[38;5;241m.\u001b[39mset_weights(model_to_clone\u001b[38;5;241m.\u001b[39mget_weights())\n",
      "File \u001b[0;32m~/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/keras/src/models/cloning.py:527\u001b[0m, in \u001b[0;36mclone_model\u001b[0;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, Sequential):\n\u001b[0;32m--> 527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_clone_sequential_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclone_function\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, functional\u001b[38;5;241m.\u001b[39mFunctional):\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;66;03m# If the get_config() method is the same as a regular Functional\u001b[39;00m\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;66;03m# model, we're safe to use _clone_functional_model (which relies\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;66;03m# or input_tensors are passed, we attempt it anyway\u001b[39;00m\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;66;03m# in order to preserve backwards compatibility.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/keras/src/models/cloning.py:390\u001b[0m, in \u001b[0;36m_clone_sequential_model\u001b[0;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    387\u001b[0m cloned_layer \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    388\u001b[0m     _clone_layer(layer)\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, InputLayer)\n\u001b[0;32m--> 390\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mlayer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m )\n\u001b[1;32m    392\u001b[0m layers\u001b[38;5;241m.\u001b[39mappend(cloned_layer)\n",
      "File \u001b[0;32m~/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/keras/src/models/cloning.py:52\u001b[0m, in \u001b[0;36m_clone_layer\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_clone_layer\u001b[39m(layer):\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize_annotate.py:129\u001b[0m, in \u001b[0;36mQuantizeAnnotate.from_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m    125\u001b[0m layer \u001b[38;5;241m=\u001b[39m quantize_utils\u001b[38;5;241m.\u001b[39mdeserialize_layer(\n\u001b[1;32m    126\u001b[0m     layer_config, use_legacy_format\u001b[38;5;241m=\u001b[39muse_legacy_format\n\u001b[1;32m    127\u001b[0m )\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantize_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantize_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize_annotate.py:59\u001b[0m, in \u001b[0;36mQuantizeAnnotate.__init__\u001b[0;34m(self, layer, quantize_config, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a quantize annotate wrapper over a keras layer.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m  **kwargs: Additional keyword arguments to be passed to the keras layer.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mQuantizeAnnotate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/keras/src/layers/rnn/base_wrapper.py:47\u001b[0m, in \u001b[0;36mWrapper.__init__\u001b[0;34m(self, layer, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m supplied to wrapper is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m not a supported layer type. Please\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ensure wrapped layer is a valid Keras layer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m     )\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer \u001b[38;5;241m=\u001b[39m layer\n",
      "\u001b[0;31mValueError\u001b[0m: Layer <tf_keras.src.layers.reshaping.reshape.Reshape object at 0x7a5d7df5a1a0> supplied to wrapper is not a supported layer type. Please ensure wrapped layer is a valid Keras layer.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# PQAT\u001b[39;00m\n\u001b[1;32m      2\u001b[0m quant_aware_annotate_model \u001b[38;5;241m=\u001b[39m tfmot\u001b[38;5;241m.\u001b[39mquantization\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mquantize_annotate_model(\n\u001b[1;32m      3\u001b[0m               pruned_model_unstructured_for_export)\n\u001b[0;32m----> 5\u001b[0m pruned_qat_model \u001b[38;5;241m=\u001b[39m \u001b[43mtfmot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantize_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquant_aware_annotate_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mtfmot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDefault8BitPrunePreserveQuantizeScheme\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m pruned_qat_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m                 loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     10\u001b[0m                 metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     12\u001b[0m pruned_qat_model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/keras/metrics.py:74\u001b[0m, in \u001b[0;36mMonitorBoolGauge.__call__.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m     73\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbool_gauge\u001b[38;5;241m.\u001b[39mget_cell(MonitorBoolGauge\u001b[38;5;241m.\u001b[39m_FAILURE_LABEL)\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 74\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "File \u001b[0;32m~/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/keras/metrics.py:69\u001b[0m, in \u001b[0;36mMonitorBoolGauge.__call__.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     68\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbool_gauge\u001b[38;5;241m.\u001b[39mget_cell(MonitorBoolGauge\u001b[38;5;241m.\u001b[39m_SUCCESS_LABEL)\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py:462\u001b[0m, in \u001b[0;36mquantize_apply\u001b[0;34m(model, scheme, quantized_layer_name_prefix)\u001b[0m\n\u001b[1;32m    460\u001b[0m   model_copy \u001b[38;5;241m=\u001b[39m _clone_model_with_weights(model)\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m er:\n\u001b[0;32m--> 462\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    463\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnable to clone model. This generally happens if you used custom \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    464\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKeras layers or objects in your model. Please specify them via \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    465\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`quantize_scope` for your calls to `quantize_model` and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    466\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`quantize_apply`. [\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m].\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m er) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mer\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_legacy_config\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    469\u001b[0m   model_copy\u001b[38;5;241m.\u001b[39muse_legacy_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39muse_legacy_config\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to clone model. This generally happens if you used custom Keras layers or objects in your model. Please specify them via `quantize_scope` for your calls to `quantize_model` and `quantize_apply`. [Layer <tf_keras.src.layers.reshaping.reshape.Reshape object at 0x7a5d7df5a1a0> supplied to wrapper is not a supported layer type. Please ensure wrapped layer is a valid Keras layer.]."
     ]
    }
   ],
   "source": [
    "# PQAT\n",
    "quant_aware_annotate_model = tfmot.quantization.keras.quantize_annotate_model(\n",
    "              pruned_model_unstructured_for_export)\n",
    "\n",
    "pruned_qat_model = tfmot.quantization.keras.quantize_apply(quant_aware_annotate_model,\n",
    "                   tfmot.experimental.combine.Default8BitPrunePreserveQuantizeScheme())\n",
    "\n",
    "pruned_qat_model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "pruned_qat_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbd76e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
