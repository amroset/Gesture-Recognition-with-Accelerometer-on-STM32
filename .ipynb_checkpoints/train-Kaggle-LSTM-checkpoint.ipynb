{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe2ec573",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 00:37:25.110853: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-30 00:37:25.132646: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-30 00:37:25.132676: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-30 00:37:25.133243: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-30 00:37:25.137272: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-30 00:37:25.598372: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU, Dropout, BatchNormalization, Conv1D, MaxPooling1D, Flatten, Input, Reshape, Conv2D, ReLU, MaxPool2D, Masking\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import ast\n",
    "\n",
    "# Load and preprocess the data\n",
    "# Replace 'train.csv' with the actual path to your dataset\n",
    "data = pd.read_csv('dataset/train.csv', header = None, converters = {\n",
    "    3: ast.literal_eval,\n",
    "    4: ast.literal_eval,\n",
    "    5: ast.literal_eval\n",
    "}, skiprows = 1)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['acc_x'] = data[3]\n",
    "df['acc_y'] = data[4]\n",
    "df['acc_z'] = data[5]\n",
    "df['gesture'] = data[2]\n",
    "\n",
    "#remove invalid rows\n",
    "df.drop(df.loc[df['acc_x']==0].index, inplace=True)\n",
    "df.drop(df.loc[df['acc_y']==0].index, inplace=True)\n",
    "df.drop(df.loc[df['acc_z']==0].index, inplace=True)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert the lists into arrays\n",
    "acc_x = df['acc_x'].values\n",
    "acc_y = df['acc_y'].values\n",
    "acc_z = df['acc_z'].values\n",
    "\n",
    "# Combine all axes into a sequence of shape (timesteps, features)\n",
    "sequences = [np.array([x, y, z]).T for x, y, z in zip(acc_x, acc_y, acc_z)]\n",
    "\n",
    "# Pad sequences to the length of the longest sequence\n",
    "padded_sequences = pad_sequences(sequences, maxlen = 32, padding='post', dtype='float32')\n",
    "\n",
    "# Encode labels\n",
    "labels = df['gesture'].values\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "categorical_labels = to_categorical(encoded_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebaa9684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA AUGMENTATION preprocessing\n",
    "\n",
    "#adding noise\n",
    "def add_noise(data, noise_level=0.05):\n",
    "    return (data + np.random.normal(0, noise_level, data.shape)).astype(np.float32)\n",
    "\n",
    "# Original data: `x_train` (accelerometer sequences), `y_train` (labels)\n",
    "\n",
    "padded_sequences = np.concatenate((padded_sequences, add_noise(padded_sequences)))\n",
    "categorical_labels = np.concatenate((categorical_labels, categorical_labels))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def scale_data(data, scaling_factor=0.1):\n",
    "    \"\"\"\n",
    "    Scale the data by a random factor.\n",
    "    Args:\n",
    "        data: Numpy array of shape (time_steps, 3).\n",
    "        scaling_factor: Max scaling factor variation.\n",
    "    Returns:\n",
    "        Scaled data.\n",
    "    \"\"\"\n",
    "    factor = 1 + np.random.uniform(-scaling_factor, scaling_factor)\n",
    "    return (data * factor).astype(np.float32)\n",
    "\n",
    "padded_sequences = np.concatenate((padded_sequences, scale_data(padded_sequences)))\n",
    "categorical_labels = np.concatenate((categorical_labels, categorical_labels))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c22ed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "    padded_sequences, categorical_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train, y_train, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81763a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.8129 - accuracy: 0.1352 - val_loss: 2.5912 - val_accuracy: 0.3728\n",
      "Epoch 2/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.3553 - accuracy: 0.2844 - val_loss: 2.0649 - val_accuracy: 0.6504\n",
      "Epoch 3/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.0073 - accuracy: 0.3829 - val_loss: 1.6345 - val_accuracy: 0.7908\n",
      "Epoch 4/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1.7616 - accuracy: 0.4554 - val_loss: 1.2345 - val_accuracy: 0.8439\n",
      "Epoch 5/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1.5326 - accuracy: 0.5300 - val_loss: 0.8750 - val_accuracy: 0.8974\n",
      "Epoch 6/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1.3865 - accuracy: 0.5659 - val_loss: 0.6562 - val_accuracy: 0.9167\n",
      "Epoch 7/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1.2813 - accuracy: 0.5946 - val_loss: 0.5496 - val_accuracy: 0.9039\n",
      "Epoch 8/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1.1581 - accuracy: 0.6421 - val_loss: 0.4428 - val_accuracy: 0.9338\n",
      "Epoch 9/20\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 1.0855 - accuracy: 0.6620 - val_loss: 0.3770 - val_accuracy: 0.9298\n",
      "Epoch 10/20\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 1.0322 - accuracy: 0.6637 - val_loss: 0.3290 - val_accuracy: 0.9408\n",
      "Epoch 11/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.9641 - accuracy: 0.6918 - val_loss: 0.2974 - val_accuracy: 0.9430\n",
      "Epoch 12/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.9388 - accuracy: 0.6833 - val_loss: 0.2646 - val_accuracy: 0.9513\n",
      "Epoch 13/20\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 0.8946 - accuracy: 0.7038 - val_loss: 0.2364 - val_accuracy: 0.9531\n",
      "Epoch 14/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.8815 - accuracy: 0.7080 - val_loss: 0.2168 - val_accuracy: 0.9504\n",
      "Epoch 15/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.8425 - accuracy: 0.7199 - val_loss: 0.2082 - val_accuracy: 0.9588\n",
      "Epoch 16/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.8022 - accuracy: 0.7377 - val_loss: 0.2038 - val_accuracy: 0.9539\n",
      "Epoch 17/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.7902 - accuracy: 0.7387 - val_loss: 0.1741 - val_accuracy: 0.9654\n",
      "Epoch 18/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.7813 - accuracy: 0.7408 - val_loss: 0.1712 - val_accuracy: 0.9553\n",
      "Epoch 19/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.7615 - accuracy: 0.7399 - val_loss: 0.1586 - val_accuracy: 0.9618\n",
      "Epoch 20/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.7394 - accuracy: 0.7560 - val_loss: 0.1558 - val_accuracy: 0.9658\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.1379 - accuracy: 0.9750\n",
      "Test Loss: 0.13793613016605377, Test Accuracy: 0.9750000238418579\n",
      "72/72 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amroset/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Neural network model\n",
    "model = Sequential([\n",
    "    Input(shape=(32, 3)),\n",
    "    # Mask padding values\n",
    "    #Masking(mask_value=0.0, input_shape=(None, 3)),\n",
    "    Reshape((8,4,3)),\n",
    "    Conv2D(filters=32, kernel_size = (3,3), padding = \"same\"),\n",
    "    Dropout(0.3),\n",
    "    BatchNormalization(),\n",
    "    ReLU(),\n",
    "    Conv2D(filters=16, kernel_size = (3,3), padding= \"same\"),\n",
    "    Dropout(0.4),\n",
    "    BatchNormalization(),\n",
    "    ReLU(),\n",
    "    MaxPool2D(pool_size = 2),\n",
    "    \n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(16),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    ReLU(),\n",
    "\n",
    "    Dense(len(label_encoder.classes_), activation = 'softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_validation, y_validation),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Save the model\n",
    "model.save('cnn_gesture_classification_model.h5')\n",
    "\n",
    "# Decode predicted labels for interpretability\n",
    "predicted_classes = label_encoder.inverse_transform(np.argmax(model.predict(X_test), axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d25fb062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 8, 4, 3)           0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 8, 4, 32)          896       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 8, 4, 32)          0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 8, 4, 32)          128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 8, 4, 32)          0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 8, 4, 16)          4624      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 4, 16)          0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 8, 4, 16)          64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 8, 4, 16)          0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 4, 2, 16)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                2064      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 16)                64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                340       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8180 (31.95 KB)\n",
      "Trainable params: 8052 (31.45 KB)\n",
      "Non-trainable params: 128 (512.00 Byte)\n",
      "_________________________________________________________________\n",
      "[[[-1.2557602e+00  5.4058933e-01 -1.1737059e-01]\n",
      "  [-1.3707398e+00  6.1314195e-01  8.2159497e-02]\n",
      "  [-1.9839656e+00 -1.1238562e-01  6.8074757e-01]\n",
      "  ...\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      " [[-1.4486126e+00  5.5310810e-01 -8.1501734e-01]\n",
      "  [-1.5441809e+00  6.3740516e-01 -8.7771106e-01]\n",
      "  [-2.1494460e+00  2.7211741e-01 -1.8808056e-01]\n",
      "  ...\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      " [[ 1.3719976e+00 -1.8916695e+00  8.7365508e-01]\n",
      "  [ 1.4641467e+00 -1.8086711e+00  8.7365508e-01]\n",
      "  [ 1.4027140e+00 -1.6426744e+00  8.4300053e-01]\n",
      "  ...\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-3.7005320e-01 -4.7556555e-01 -3.7111297e-01]\n",
      "  [-3.6154714e-01 -4.4526625e-01 -2.2201154e-01]\n",
      "  [-1.1857409e-01  1.5678565e-01  7.0024174e-01]\n",
      "  ...\n",
      "  [-4.1283011e-02 -5.0897654e-02  7.8476667e-02]\n",
      "  [ 3.3522490e-02  2.7729262e-02  2.1438608e-02]\n",
      "  [ 5.6518503e-03 -2.2273311e-04 -5.7298881e-03]]\n",
      "\n",
      " [[ 1.0984508e+00 -1.1503510e+00 -1.8607451e-01]\n",
      "  [ 1.2662809e+00 -1.1114023e+00 -2.0375226e-01]\n",
      "  [ 1.1421416e+00 -2.8687632e-01  1.3315347e+00]\n",
      "  ...\n",
      "  [-1.9197322e-02  2.3247616e-02  7.5149797e-02]\n",
      "  [ 4.2761356e-02  6.5535598e-02  6.7957781e-02]\n",
      "  [-9.4239868e-02  9.4548590e-02 -7.9020493e-02]]\n",
      "\n",
      " [[ 1.0289472e+00 -9.4317275e-01 -5.9357637e-01]\n",
      "  [ 1.1110893e+00 -9.2889667e-01 -5.6401432e-01]\n",
      "  [ 9.0717906e-01 -1.0839900e+00 -6.4845282e-01]\n",
      "  ...\n",
      "  [-3.4172742e-03 -6.5878101e-02  1.5954863e-02]\n",
      "  [-1.1187988e-02  1.7590420e-02 -2.4173878e-02]\n",
      "  [-1.2871552e-01 -2.7141903e-02 -4.5399029e-02]]]\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "Predictions saved to test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "#Inference\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('cnn_gesture_classification_model.h5')\n",
    "model.summary()\n",
    "\n",
    "print(padded_sequences)\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv('dataset/test.csv', header=None, converters={\n",
    "    2: ast.literal_eval,\n",
    "    3: ast.literal_eval,\n",
    "    4: ast.literal_eval\n",
    "}, skiprows=1)\n",
    "\n",
    "# Preprocess the test data\n",
    "df_test = pd.DataFrame()\n",
    "df_test['acc_x'] = test_data[2]\n",
    "df_test['acc_y'] = test_data[3]\n",
    "df_test['acc_z'] = test_data[4]\n",
    "\n",
    "# Ensure all data is consistent (dropping invalid or zero entries)\n",
    "df_test.drop(df_test.loc[df_test['acc_x'] == 0].index, inplace=True)\n",
    "df_test.drop(df_test.loc[df_test['acc_y'] == 0].index, inplace=True)\n",
    "df_test.drop(df_test.loc[df_test['acc_z'] == 0].index, inplace=True)\n",
    "\n",
    "df_test = df_test.dropna()\n",
    "\n",
    "# Extract accelerometer data (acc_x, acc_y, acc_z) for the test set\n",
    "acc_x = df_test['acc_x'].values\n",
    "acc_y = df_test['acc_y'].values\n",
    "acc_z = df_test['acc_z'].values\n",
    "\n",
    "test_sequences = [np.array([x, y, z]).T for x, y, z in zip(acc_x, acc_y, acc_z)]\n",
    "\n",
    "# Pad sequences to the length of the longest sequence\n",
    "padded_test_sequences = pad_sequences(test_sequences, padding='post', dtype='float32')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(padded_test_sequences)\n",
    "\n",
    "# Decode predictions to gesture classes\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# If you used a LabelEncoder for training, decode the classes\n",
    "# Replace 'label_encoder' with your encoder used during training\n",
    "gesture_labels = label_encoder.inverse_transform(predicted_classes)\n",
    "\n",
    "df_out = pd.DataFrame()\n",
    "df_out['id'] = test_data[0]\n",
    "df_out['gesture'] = gesture_labels\n",
    "\n",
    "\n",
    "# Save the results\n",
    "df_out.to_csv('cnn_test_predictions.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to test_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d07945f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp1wf7xys8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp1wf7xys8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with full integer quantization saved as gesture_classification_model_integer.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amroset/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-12-30 00:37:49.185123: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-12-30 00:37:49.185139: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-12-30 00:37:49.185336: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp1wf7xys8\n",
      "2024-12-30 00:37:49.186995: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-12-30 00:37:49.187004: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp1wf7xys8\n",
      "2024-12-30 00:37:49.190522: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-12-30 00:37:49.191666: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-12-30 00:37:49.241773: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp1wf7xys8\n",
      "2024-12-30 00:37:49.256129: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 70792 microseconds.\n",
      "2024-12-30 00:37:49.272401: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 14, Total Ops 28, % non-converted = 50.00 %\n",
      " * 14 ARITH ops\n",
      "\n",
      "- arith.constant:   14 occurrences  (f32: 8, i32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 2)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (i32: 1)\n",
      "  (f32: 2)\n",
      "  (i32: 1)\n",
      "  (f32: 1)\n",
      "  (i32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(padded_sequences).batch(1).take(32):\n",
    "    yield [input_value]\n",
    "        \n",
    "# Ensure input shape is fixed\n",
    "model.build(input_shape=(None, 32, 3))  # Example: Fixed length 32 timesteps, 3 features\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# Apply integer quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]  # Ensure compatibility\n",
    "converter.inference_input_type = tf.uint8  # Optional: Set input type\n",
    "converter.inference_output_type = tf.uint8  # Optional: Set output type\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model\n",
    "with open('cnn_gesture_classification_model_integer.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Model with full integer quantization saved as gesture_classification_model_integer.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94fc5796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpkqzhqnjh/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpkqzhqnjh/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDF5 Model size without quantization: 442 KB\n",
      "TFLite Model size without quantization: 35 KB\n",
      "\n",
      "Reduction in file size by a factor of 12.375984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 00:37:52.289228: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-12-30 00:37:52.289244: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-12-30 00:37:52.289344: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpkqzhqnjh\n",
      "2024-12-30 00:37:52.290940: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-12-30 00:37:52.290955: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpkqzhqnjh\n",
      "2024-12-30 00:37:52.295056: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-12-30 00:37:52.340014: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpkqzhqnjh\n",
      "2024-12-30 00:37:52.352383: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 63038 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 14, Total Ops 28, % non-converted = 50.00 %\n",
      " * 14 ARITH ops\n",
      "\n",
      "- arith.constant:   14 occurrences  (f32: 8, i32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 2)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (i32: 1)\n",
      "  (f32: 2)\n",
      "  (i32: 1)\n",
      "  (f32: 1)\n",
      "  (i32: 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Convert the model to TFLite without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "fp_tflite_model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(\"cnn_model_f32.tflite\", \"wb\").write(fp_tflite_model)\n",
    "\n",
    "# Show the model size for the non-quantized HDF5 model\n",
    "fp_h5_in_kb = os.path.getsize('models/gesture_classification_model.h5') / 1024\n",
    "print(\"HDF5 Model size without quantization: %d KB\" % fp_h5_in_kb)\n",
    "\n",
    "# Show the model size for the non-quantized TFLite model\n",
    "fp_tflite_in_kb = os.path.getsize('cnn_model_f32.tflite') / 1024\n",
    "print(\"TFLite Model size without quantization: %d KB\" % fp_tflite_in_kb)\n",
    "\n",
    "# Determine the reduction in model size\n",
    "print(\"\\nReduction in file size by a factor of %f\" % (fp_h5_in_kb / fp_tflite_in_kb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90af0a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.uint8'>\n",
      "output:  <class 'numpy.uint8'>\n",
      "TFLite Model size with 8-bit quantization: 14 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "WARNING: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors (tensor#19 is a dynamic-sized tensor).\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)\n",
    "\n",
    "# Show the model size for the 8-bit quantized TFLite model\n",
    "tflite_quant_in_kb = os.path.getsize('models/cnn_gesture_classification_model_integer.tflite') / 1024\n",
    "print(\"TFLite Model size with 8-bit quantization: %d KB\" % tflite_quant_in_kb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1ff3df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Helper function to run inference on a TFLite model\n",
    "\n",
    "test_sequence_indices = range(X_test.shape[0])\n",
    "\n",
    "print(y_test)\n",
    "\n",
    "def run_tflite_model(tflite_file, test_image_indices):\n",
    "  global X_test\n",
    "\n",
    "  # Initialize the interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  predictions = []\n",
    "  for i, test_sequence_index in enumerate(test_sequence_indices):\n",
    "    test_sequence = X_test[test_sequence_index]\n",
    "    test_label = y_test[test_sequence_index]\n",
    "\n",
    "    if (test_sequence_index % 100 == 0):\n",
    "      print(\"Evaluated on %d sequences.\" % test_sequence_index)\n",
    "\n",
    "    # Check if the input type is quantized, then rescale input data to uint8\n",
    "    if input_details['dtype'] == np.uint8:\n",
    "      input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "      test_sequence = test_sequence / input_scale + input_zero_point\n",
    "\n",
    "    test_sequence = np.expand_dims(test_sequence, axis=0).astype(input_details[\"dtype\"])\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_sequence)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "    predictions.append(np.argmax(output, axis=-1))\n",
    "\n",
    "  return predictions\n",
    "\n",
    "\n",
    "# Helper function to evaluate a TFLite model on all images\n",
    "def evaluate_model(tflite_file, model_type):\n",
    "  global X_test\n",
    "  global y_test\n",
    "\n",
    "  test_sequence_indices = range(X_train.shape[0])\n",
    "  predictions = run_tflite_model(tflite_file, test_sequence_indices)\n",
    "    \n",
    "  labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "  accuracy = (np.sum(labels == predictions) * 100) / len(X_test)\n",
    "\n",
    "  print('%s model accuracy is %.4f%% (Number of test samples=%d)' % (\n",
    "      model_type, accuracy, len(X_test)))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60907cd0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 sequences.\n",
      "Evaluated on 100 sequences.\n",
      "Evaluated on 200 sequences.\n",
      "Evaluated on 300 sequences.\n",
      "Evaluated on 400 sequences.\n",
      "Evaluated on 500 sequences.\n",
      "Evaluated on 600 sequences.\n",
      "Evaluated on 700 sequences.\n",
      "Evaluated on 800 sequences.\n",
      "Evaluated on 900 sequences.\n",
      "Evaluated on 1000 sequences.\n",
      "Evaluated on 1100 sequences.\n",
      "Evaluated on 1200 sequences.\n",
      "Evaluated on 1300 sequences.\n",
      "Evaluated on 1400 sequences.\n",
      "Evaluated on 1500 sequences.\n",
      "Evaluated on 1600 sequences.\n",
      "Evaluated on 1700 sequences.\n",
      "Evaluated on 1800 sequences.\n",
      "Evaluated on 1900 sequences.\n",
      "Evaluated on 2000 sequences.\n",
      "Evaluated on 2100 sequences.\n",
      "Evaluated on 2200 sequences.\n",
      "Full Post-Quantized INT8 model accuracy is 95.9211% (Number of test samples=2280)\n",
      "0.026128482073545456\n",
      "119\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "# this might take a few minutes (~ 1- 2 minutes)\n",
    "# if it takes longer than that, I suggest to \n",
    "# restart the runtime and try again\n",
    "# if the issue still persists, restart your computer\n",
    "tflite_model_quant_int8_file = pathlib.Path('models/cnn_gesture_classification_model_integer.tflite')\n",
    "tflite_model_quant_int8_model_type = \"Full Post-Quantized INT8\"\n",
    "\n",
    "evaluate_model(tflite_model_quant_int8_file, tflite_model_quant_int8_model_type)\n",
    "\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "\n",
    "print(input_scale)\n",
    "print(input_zero_point)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f5cb06e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 sequences.\n",
      "Evaluated on 100 sequences.\n",
      "Evaluated on 200 sequences.\n",
      "Evaluated on 300 sequences.\n",
      "Evaluated on 400 sequences.\n",
      "Evaluated on 500 sequences.\n",
      "Evaluated on 600 sequences.\n",
      "Evaluated on 700 sequences.\n",
      "Evaluated on 800 sequences.\n",
      "Evaluated on 900 sequences.\n",
      "Evaluated on 1000 sequences.\n",
      "Evaluated on 1100 sequences.\n",
      "Evaluated on 1200 sequences.\n",
      "Evaluated on 1300 sequences.\n",
      "Evaluated on 1400 sequences.\n",
      "Evaluated on 1500 sequences.\n",
      "Evaluated on 1600 sequences.\n",
      "Evaluated on 1700 sequences.\n",
      "Evaluated on 1800 sequences.\n",
      "Evaluated on 1900 sequences.\n",
      "Evaluated on 2000 sequences.\n",
      "Evaluated on 2100 sequences.\n",
      "Evaluated on 2200 sequences.\n",
      "Full-precision model accuracy is 97.5000% (Number of test samples=2280)\n",
      "Quantized model accuracy is 95.9211% (Number of test samples=2280)\n"
     ]
    }
   ],
   "source": [
    "# we plot also the confusion matrix of the quantized model\n",
    "tflite_model_quant_int8_pred = run_tflite_model(tflite_model_quant_int8_file, range(y_test.shape[0]))\n",
    "\n",
    "# compute the accuracy of the quantized model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "full_int8_accuracy = accuracy_score(labels, tflite_model_quant_int8_pred)\n",
    "print(\"Full-precision model accuracy is %.4f%% (Number of test samples=%d)\" % (test_accuracy * 100, len(y_test)))\n",
    "print(\"Quantized model accuracy is %.4f%% (Number of test samples=%d)\" % (full_int8_accuracy * 100, len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02a86b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Convert some hex value into an array for C programming\n",
    "def hex_to_c_array(hex_data, var_name):\n",
    "\n",
    "    c_str = ''\n",
    "\n",
    "    # Create header guard\n",
    "    c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n",
    "    c_str += '#define ' + var_name.upper() + '_H\\n\\n'\n",
    "\n",
    "    # Add array length at top of file\n",
    "    c_str += '\\nstatic const unsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n",
    "\n",
    "    # Declare C variable\n",
    "    c_str += 'static const unsigned char ' + var_name + '[] = {'\n",
    "    hex_array = []\n",
    "    for i, val in enumerate(hex_data) :\n",
    "\n",
    "        # Construct string from hex\n",
    "        hex_str = format(val, '#04x')\n",
    "\n",
    "        # Add formatting so each line stays within 80 characters\n",
    "        if (i + 1) < len(hex_data):\n",
    "            hex_str += ','\n",
    "        if (i + 1) % 12 == 0:\n",
    "            hex_str += '\\n '\n",
    "        hex_array.append(hex_str)\n",
    "\n",
    "    # Add closing brace\n",
    "    c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n",
    "\n",
    "    # Close out header guard\n",
    "    c_str += '#endif //' + var_name.upper() + '_H'\n",
    "\n",
    "    return c_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0392b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_model_name = 'q8_cnn'\n",
    "# check if dir 'cfiles' exists, if not create it\n",
    "if not os.path.exists('cfiles'):\n",
    "    os.makedirs('cfiles')\n",
    "# Write TFLite model to a C source (or header) file\n",
    "with open('cfiles/' + c_model_name + '.h', 'w') as file:\n",
    "    file.write(hex_to_c_array(tflite_model, c_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4445fc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image data location:  /home/amroset/Machine Learning on Microcontrollers/Project/x_test_gestures.npy\n",
      "Test labels location:  /home/amroset/Machine Learning on Microcontrollers/Project/y_test_gestures.npy\n"
     ]
    }
   ],
   "source": [
    "input_details = interpreter.get_input_details()[0]\n",
    "input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "\n",
    "# save the test data as numpy arrays\n",
    "np.save('x_test_gestures.npy', (X_test / input_scale + input_zero_point).astype(np.uint8))\n",
    "np.save('y_test_gestures.npy', (y_test.astype(np.uint8)))\n",
    "\n",
    "# print the location of the files\n",
    "print('Test image data location: ', os.path.abspath('x_test_gestures.npy'))\n",
    "print('Test labels location: ', os.path.abspath('y_test_gestures.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a7a8d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026128482073545456\n",
      "119\n",
      "[[-1.2017318   0.16807531  0.15167339]\n",
      " [-1.2530056   0.16807531  0.15167339]\n",
      " [-1.1504579   0.16807531  0.15167339]\n",
      " [-1.1504579   0.20704933  0.28464743]\n",
      " [-0.27880186  1.3762691   0.7832997 ]\n",
      " [-0.02243226  2.5844631   0.1849169 ]\n",
      " [ 0.38775876 -1.6637025  -0.11427449]\n",
      " [-1.6631967  -1.8585724  -1.7432058 ]\n",
      " [ 0.02884166  0.20704933 -2.2086146 ]\n",
      " [ 2.0285232  -0.10474256  2.3789873 ]\n",
      " [ 0.38775876 -0.6893526   1.1157348 ]\n",
      " [ 0.7979498  -0.6503786  -0.04778747]\n",
      " [ 0.95177156 -0.10474256 -0.08103098]\n",
      " [ 0.69540197  0.3239714  -0.4467094 ]\n",
      " [ 0.6441284  -0.06576855 -0.24724855]\n",
      " [ 0.7979498  -0.06576855 -0.31373534]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "X_test_try = (X_test[14] / input_scale + input_zero_point).astype(np.uint8)\n",
    "\n",
    "print(input_scale)\n",
    "print(input_zero_point)\n",
    "print(X_test[19])\n",
    "print(np.argmax(y_test[14]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c495ef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_test_sample_to_header(X_test_try, output_file):\n",
    "    \"\"\"\n",
    "    Extract a test sample from X_test and write it to a data.h file.\n",
    "    \n",
    "    Args:\n",
    "        X_test (np.ndarray): The test dataset.\n",
    "        sample_index (int): Index of the sample to extract.\n",
    "        output_file (str): Path to the output .h file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Flatten the sample if it is multi-dimensional\n",
    "    flattened_sample = X_test_try.flatten()\n",
    "    \n",
    "    # Generate the C array string\n",
    "    c_array = \", \".join(map(str, flattened_sample))\n",
    "    \n",
    "    # Determine the shape of the original sample\n",
    "    original_shape = X_test_try.shape\n",
    "    \n",
    "    # Write to the header file\n",
    "    with open(output_file, \"w\") as file:\n",
    "        file.write(\"// Auto-generated header file with test data\\n\")\n",
    "        file.write(f\"#ifndef DATA_H\\n#define DATA_H\\n\\n\")\n",
    "        file.write(f\"#define SAMPLE_SIZE {len(flattened_sample)}\\n\")\n",
    "        file.write(f\"const float test_sample[SAMPLE_SIZE] = {{ {c_array} }};\\n\")\n",
    "        file.write(f\"// Original shape: {original_shape}\\n\")\n",
    "        file.write(\"\\n#endif // DATA_H\\n\")\n",
    "\n",
    "# Example usage\n",
    "output_file = \"data.h\"\n",
    "write_test_sample_to_header(X_test_try, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1362800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qkeras import *\n",
    "import gc\n",
    "\n",
    "def get_cnn_quantized_model(num_classes):\n",
    "\n",
    "        gc.collect()\n",
    "        keras.backend.clear_session()\n",
    "    \n",
    "    \n",
    "        #qkeras model\n",
    "\n",
    "        quantized_model = keras.Sequential([\n",
    "                        keras.layers.Input((32,3)),\n",
    "                        keras.layers.Reshape((8,4,3)),\n",
    "                        #QActivation(\"quantized_bits(16)\"),\n",
    "                        QConv2D(filters=8, kernel_size = (5,5), padding = \"same\", kernel_quantizer=\"quantized_bits(8)\"),\n",
    "                        keras.layers.BatchNormalization(),\n",
    "                        QActivation(\"quantized_relu(8)\"),\n",
    "                        QConv2D(filters=8, kernel_size = (5,5), padding = \"same\", kernel_quantizer=\"quantized_bits(8)\"),\n",
    "                        keras.layers.BatchNormalization(),\n",
    "                        QActivation(\"quantized_relu(8)\"),\n",
    "                        keras.layers.MaxPool2D(pool_size = 2),\n",
    "                        keras.layers.Flatten(),\n",
    "                        QDense(32, kernel_quantizer=\"quantized_bits(8)\"),\n",
    "                        keras.layers.BatchNormalization(),\n",
    "                        QActivation(\"quantized_relu(8)\"),\n",
    "                        QDense(num_classes, kernel_quantizer=\"quantized_bits(8)\"),\n",
    "                        keras.layers.Activation('softmax'),\n",
    "                        ])\n",
    "\n",
    "        return quantized_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "102f0e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 8, 4, 3)           0         \n",
      "                                                                 \n",
      " q_conv2d (QConv2D)          (None, 8, 4, 8)           608       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 8, 4, 8)           32        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " q_activation (QActivation)  (None, 8, 4, 8)           0         \n",
      "                                                                 \n",
      " q_conv2d_1 (QConv2D)        (None, 8, 4, 8)           1608      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 8, 4, 8)           32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " q_activation_1 (QActivatio  (None, 8, 4, 8)           0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 4, 2, 8)           0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " q_dense (QDense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 32)                128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " q_activation_2 (QActivatio  (None, 32)                0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " q_dense_1 (QDense)          (None, 20)                660       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 20)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5148 (20.11 KB)\n",
      "Trainable params: 5052 (19.73 KB)\n",
      "Non-trainable params: 96 (384.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "qmodel = get_cnn_quantized_model(len(label_encoder.classes_))\n",
    "\n",
    "qmodel.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "qmodel.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "25606dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "214/214 [==============================] - 2s 4ms/step - loss: 2.3573 - accuracy: 0.3563 - val_loss: 1.8706 - val_accuracy: 0.5825 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 1.4135 - accuracy: 0.7453 - val_loss: 1.1697 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 0.8860 - accuracy: 0.8596 - val_loss: 0.7265 - val_accuracy: 0.8825 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.5742 - accuracy: 0.9152 - val_loss: 0.5060 - val_accuracy: 0.9197 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.4037 - accuracy: 0.9443 - val_loss: 0.3527 - val_accuracy: 0.9456 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.2972 - accuracy: 0.9607 - val_loss: 0.2917 - val_accuracy: 0.9557 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.2309 - accuracy: 0.9725 - val_loss: 0.2208 - val_accuracy: 0.9675 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 0.1866 - accuracy: 0.9775 - val_loss: 0.1801 - val_accuracy: 0.9711 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 0.1510 - accuracy: 0.9814 - val_loss: 0.1491 - val_accuracy: 0.9754 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.1272 - accuracy: 0.9848 - val_loss: 0.1297 - val_accuracy: 0.9825 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.1083 - accuracy: 0.9880 - val_loss: 0.1079 - val_accuracy: 0.9846 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.0916 - accuracy: 0.9905 - val_loss: 0.0961 - val_accuracy: 0.9882 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.0791 - accuracy: 0.9923 - val_loss: 0.0836 - val_accuracy: 0.9877 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.0680 - accuracy: 0.9946 - val_loss: 0.0765 - val_accuracy: 0.9868 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.0582 - accuracy: 0.9947 - val_loss: 0.0630 - val_accuracy: 0.9904 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.0542 - accuracy: 0.9955 - val_loss: 0.0508 - val_accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 0.0517 - accuracy: 0.9944 - val_loss: 0.0507 - val_accuracy: 0.9934 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.0451 - accuracy: 0.9955 - val_loss: 0.0441 - val_accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.0379 - accuracy: 0.9975 - val_loss: 0.0385 - val_accuracy: 0.9930 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 0.0350 - accuracy: 0.9972 - val_loss: 0.0377 - val_accuracy: 0.9934 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x723596bff4f0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate the quantization aware model\n",
    "es = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_delta=0.0001, mode='auto', cooldown=0, min_lr=0)\n",
    "                \n",
    "    ]\n",
    "qmodel.fit(\n",
    "                  X_train,\n",
    "                  y_train,\n",
    "                  epochs=20,\n",
    "                  validation_data=(X_validation, y_validation),\n",
    "                  callbacks=[es]\n",
    "              )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1e873400",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization aware training loss:  0.040925752371549606\n",
      "Quantization aware training accuracy:  0.9929824471473694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amroset/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "/home/amroset/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/keras/src/constraints.py:365: UserWarning: The `keras.constraints.serialize()` API should only be used for objects of type `keras.constraints.Constraint`. Found an instance of type <class 'qkeras.quantizers.quantized_bits'>, which may lead to improper serialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the test set\n",
    "quant_loss, quant_acc = qmodel.evaluate(X_test, y_test, verbose=0)\n",
    "print('Quantization aware training loss: ', quant_loss)\n",
    "print('Quantization aware training accuracy: ', quant_acc)\n",
    "qmodel.save('qat_cnn_gesture_classification_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7de46094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp4yqthdn9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp4yqthdn9/assets\n",
      "/home/amroset/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-12-29 19:17:45.985105: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-12-29 19:17:45.985124: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-12-29 19:17:45.985230: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp4yqthdn9\n",
      "2024-12-29 19:17:45.988489: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-12-29 19:17:45.988500: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp4yqthdn9\n",
      "2024-12-29 19:17:45.997999: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-12-29 19:17:46.059358: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp4yqthdn9\n",
      "2024-12-29 19:17:46.086235: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 101002 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 20, Total Ops 79, % non-converted = 25.32 %\n",
      " * 20 ARITH ops\n",
      "\n",
      "- arith.constant:   20 occurrences  (f32: 14, i32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 6)\n",
      "  (f32: 3)\n",
      "  (f32: 2)\n",
      "  (f32: 4)\n",
      "  (i1: 3)\n",
      "  (f32: 1)\n",
      "  (f32: 3)\n",
      "  (f32: 8)\n",
      "  (i32: 1)\n",
      "  (f32: 5)\n",
      "  (f32: 2)\n",
      "  (f32: 3)\n",
      "  (f32: 3)\n",
      "  (i64: 3, i32: 1)\n",
      "  (f32: 1)\n",
      "  (i32: 1)\n",
      "  (f32: 6)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    }
   ],
   "source": [
    "# convert the QAT model to a fully quantized model using TFLite\n",
    "\n",
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(X_train).batch(1).take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(qmodel)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant_int8_qat = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d53c758a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.uint8'>\n",
      "output:  <class 'numpy.uint8'>\n",
      "TFLite Model size with 8-bit quantization: 22 KB\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant_int8_qat)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)\n",
    "# Save the quantized model to disk\n",
    "open(\"gesture_qat_int8.tflite\", \"wb\").write(tflite_model_quant_int8_qat)\n",
    "\n",
    "# Show the model size for the 8-bit quantized TFLite model\n",
    "tflite_quant_in_kb = os.path.getsize('models/gesture_qat_int8.tflite') / 1024\n",
    "print(\"TFLite Model size with 8-bit quantization: %d KB\" % tflite_quant_in_kb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "693a76de",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_model_name = 'qat8_gesture'\n",
    "# Write TFLite model to a C source (or header) file\n",
    "with open(c_model_name + '.h', 'w') as file:\n",
    "    file.write(hex_to_c_array(tflite_model_quant_int8_qat, c_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "348ac827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 sequences.\n",
      "Evaluated on 100 sequences.\n",
      "Evaluated on 200 sequences.\n",
      "Evaluated on 300 sequences.\n",
      "Evaluated on 400 sequences.\n",
      "Evaluated on 500 sequences.\n",
      "Evaluated on 600 sequences.\n",
      "Evaluated on 700 sequences.\n",
      "Evaluated on 800 sequences.\n",
      "Evaluated on 900 sequences.\n",
      "Evaluated on 1000 sequences.\n",
      "Evaluated on 1100 sequences.\n",
      "Evaluated on 1200 sequences.\n",
      "Evaluated on 1300 sequences.\n",
      "Evaluated on 1400 sequences.\n",
      "Evaluated on 1500 sequences.\n",
      "Evaluated on 1600 sequences.\n",
      "Evaluated on 1700 sequences.\n",
      "Evaluated on 1800 sequences.\n",
      "Evaluated on 1900 sequences.\n",
      "Evaluated on 2000 sequences.\n",
      "Evaluated on 2100 sequences.\n",
      "Evaluated on 2200 sequences.\n",
      "Full QAT INT8 model accuracy is 97.7632% (Number of test samples=2280)\n",
      "Full-precision model accuracy is 97.5000% (Number of test samples=6840)\n"
     ]
    }
   ],
   "source": [
    "# this might take a few minutes (~ 1- 2 minutes)\n",
    "# if it takes longer than that, I suggest to \n",
    "# restart the runtime and try again\n",
    "# if the issue still persists, restart your computer\n",
    "tflite_model_quant_int8_qat_file = pathlib.Path('models/no_qkeras_gesture_qat_int8.tflite')\n",
    "tflite_model_quant_int8_qat_type = \"Full QAT INT8\"\n",
    "\n",
    "evaluate_model(tflite_model_quant_int8_qat_file, tflite_model_quant_int8_qat_type)\n",
    "print(\"Full-precision model accuracy is %.4f%% (Number of test samples=%d)\" % (test_accuracy * 100, len(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09faa18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 sequences.\n",
      "Evaluated on 100 sequences.\n",
      "Evaluated on 200 sequences.\n",
      "Evaluated on 300 sequences.\n",
      "Evaluated on 400 sequences.\n",
      "Evaluated on 500 sequences.\n",
      "Evaluated on 600 sequences.\n",
      "Evaluated on 700 sequences.\n",
      "Evaluated on 800 sequences.\n",
      "Evaluated on 900 sequences.\n",
      "Evaluated on 1000 sequences.\n",
      "Evaluated on 1100 sequences.\n",
      "Evaluated on 1200 sequences.\n",
      "Evaluated on 1300 sequences.\n",
      "Evaluated on 1400 sequences.\n",
      "Evaluated on 1500 sequences.\n",
      "Evaluated on 1600 sequences.\n",
      "Evaluated on 1700 sequences.\n",
      "Evaluated on 1800 sequences.\n",
      "Evaluated on 1900 sequences.\n",
      "Evaluated on 2000 sequences.\n",
      "Evaluated on 2100 sequences.\n",
      "Evaluated on 2200 sequences.\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the test set\n",
    "tflite_model_quant_int8_qat_file = \"models/no_qkeras_gesture_qat_int8.tflite\"\n",
    "tflite_model_quant_int8_qat_model_type = \"Quantized aware training model\"\n",
    "tflite_model_quant_int8_qat_pred = run_tflite_model(tflite_model_quant_int8_qat_file, range(X_train.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "715b57f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full QAT INT8 accuracy is 99.2544% (Number of test samples=2280)\n",
      "Full-precision model accuracy is 97.9825% (Number of test samples=2280)\n"
     ]
    }
   ],
   "source": [
    "# compute the accuracy of the model\n",
    "full_qat_int8_accuracy = accuracy_score(labels, tflite_model_quant_int8_qat_pred)\n",
    "print('Full QAT INT8 accuracy is %.4f%% (Number of test samples=%d)' % (full_qat_int8_accuracy * 100, len(y_test)))\n",
    "print('Full-precision model accuracy is %.4f%% (Number of test samples=%d)' % (test_accuracy * 100, len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8660a71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
