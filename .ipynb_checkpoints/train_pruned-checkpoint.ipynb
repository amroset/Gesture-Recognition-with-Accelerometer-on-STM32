{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c760d22a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`to_annotate` can only be a `keras.layers.Layer` instance. You passed an instance of type: Reshape.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m layer\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tfmot\u001b[38;5;241m.\u001b[39mquantization\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mquantize_annotate_layer(layer)\n\u001b[0;32m---> 34\u001b[0m annotated_model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclone_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapply_quantization\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Apply QAT\u001b[39;00m\n\u001b[1;32m     37\u001b[0m qat_model \u001b[38;5;241m=\u001b[39m tfmot\u001b[38;5;241m.\u001b[39mquantization\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mquantize_apply(annotated_model)\n",
      "File \u001b[0;32m~/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/keras/src/models/cloning.py:527\u001b[0m, in \u001b[0;36mclone_model\u001b[0;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m serialization\u001b[38;5;241m.\u001b[39mDisableSharedObjectScope():\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, Sequential):\n\u001b[0;32m--> 527\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_clone_sequential_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclone_function\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, functional\u001b[38;5;241m.\u001b[39mFunctional):\n\u001b[1;32m    531\u001b[0m         \u001b[38;5;66;03m# If the get_config() method is the same as a regular Functional\u001b[39;00m\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;66;03m# model, we're safe to use _clone_functional_model (which relies\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[38;5;66;03m# or input_tensors are passed, we attempt it anyway\u001b[39;00m\n\u001b[1;32m    536\u001b[0m         \u001b[38;5;66;03m# in order to preserve backwards compatibility.\u001b[39;00m\n\u001b[1;32m    537\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generic_utils\u001b[38;5;241m.\u001b[39mis_default(model\u001b[38;5;241m.\u001b[39mget_config) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    538\u001b[0m             clone_function \u001b[38;5;129;01mor\u001b[39;00m input_tensors\n\u001b[1;32m    539\u001b[0m         ):\n",
      "File \u001b[0;32m~/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/keras/src/models/cloning.py:390\u001b[0m, in \u001b[0;36m_clone_sequential_model\u001b[0;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, InputLayer) \u001b[38;5;129;01mand\u001b[39;00m input_tensors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# If input tensors are provided, the original model's InputLayer is\u001b[39;00m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;66;03m# overwritten with a different InputLayer.\u001b[39;00m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    387\u001b[0m cloned_layer \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    388\u001b[0m     _clone_layer(layer)\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, InputLayer)\n\u001b[0;32m--> 390\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mlayer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m )\n\u001b[1;32m    392\u001b[0m layers\u001b[38;5;241m.\u001b[39mappend(cloned_layer)\n\u001b[1;32m    393\u001b[0m layer_map[layer] \u001b[38;5;241m=\u001b[39m cloned_layer\n",
      "Cell \u001b[0;32mIn[22], line 32\u001b[0m, in \u001b[0;36mapply_quantization\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mBatchNormalization):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtfmot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantize_annotate_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py:270\u001b[0m, in \u001b[0;36mquantize_annotate_layer\u001b[0;34m(to_annotate, quantize_config)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# Check against keras.Model since it is an instance of keras.layers.Layer.\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(to_annotate, keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLayer) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    269\u001b[0m     to_annotate, keras\u001b[38;5;241m.\u001b[39mModel):\n\u001b[0;32m--> 270\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    271\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`to_annotate` can only be a `keras.layers.Layer` instance. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    272\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou passed an instance of type: \u001b[39m\u001b[38;5;132;01m{input}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    273\u001b[0m           \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mto_annotate\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    274\u001b[0m       )\n\u001b[1;32m    275\u001b[0m   )\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m quantize_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    278\u001b[0m     quantize_config, quantize_config_mod\u001b[38;5;241m.\u001b[39mQuantizeConfig):\n\u001b[1;32m    279\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    280\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`quantize_config` can only be a `tfmot.quantization.keras.QuantizeConfig` instance.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    281\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou passed an instance of type: \u001b[39m\u001b[38;5;132;01m{input}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    282\u001b[0m           \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mquantize_config\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n",
      "\u001b[0;31mValueError\u001b[0m: `to_annotate` can only be a `keras.layers.Layer` instance. You passed an instance of type: Reshape."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "    \n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(32, 3)),\n",
    "    tf.keras.layers.Reshape((8, 4, 3)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\"),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Conv2D(filters=12, kernel_size = (3,3), padding= \"same\"),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.MaxPool2D(pool_size = 2),\n",
    "    \n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(16),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "\n",
    "    tf.keras.layers.Dense(20, activation='softmax')\n",
    "])\n",
    "\n",
    "# Annotate the model for QAT, skipping BatchNorm.\n",
    "def apply_quantization(layer):\n",
    "    # Skip quantization for unsupported layers\n",
    "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        return layer\n",
    "    return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
    "\n",
    "annotated_model = tf.keras.models.clone_model(model, clone_function=apply_quantization)\n",
    "\n",
    "# Apply QAT\n",
    "qat_model = tfmot.quantization.keras.quantize_apply(annotated_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bf8a42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quantize_layer (QuantizeLa  (None, 32, 3)             3         \n",
      " yer)                                                            \n",
      "                                                                 \n",
      " quant_reshape (QuantizeWra  (None, 8, 4, 3)           1         \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_conv2d (QuantizeWrap  (None, 8, 4, 32)          963       \n",
      " perV2)                                                          \n",
      "                                                                 \n",
      " quant_dropout (QuantizeWra  (None, 8, 4, 32)          1         \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 8, 4, 32)          128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " quant_re_lu (QuantizeWrapp  (None, 8, 4, 32)          3         \n",
      " erV2)                                                           \n",
      "                                                                 \n",
      " quant_conv2d_1 (QuantizeWr  (None, 8, 4, 12)          3495      \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_dropout_1 (QuantizeW  (None, 8, 4, 12)          1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 8, 4, 12)          48        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " quant_re_lu_1 (QuantizeWra  (None, 8, 4, 12)          3         \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_max_pooling2d (Quant  (None, 4, 2, 12)          1         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " quant_flatten (QuantizeWra  (None, 96)                1         \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense (QuantizeWrapp  (None, 16)                1557      \n",
      " erV2)                                                           \n",
      "                                                                 \n",
      " quant_dropout_2 (QuantizeW  (None, 16)                1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 16)                64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " quant_re_lu_2 (QuantizeWra  (None, 16)                3         \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense_1 (QuantizeWra  (None, 20)                345       \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6618 (25.85 KB)\n",
      "Trainable params: 6376 (24.91 KB)\n",
      "Non-trainable params: 242 (968.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "qat_model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "qat_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3556e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load and preprocess the data\n",
    "# Replace 'train.csv' with the actual path to your dataset\n",
    "data = pd.read_csv('dataset/train.csv', header = None, converters = {\n",
    "    3: ast.literal_eval,\n",
    "    4: ast.literal_eval,\n",
    "    5: ast.literal_eval\n",
    "}, skiprows = 1)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['acc_x'] = data[3]\n",
    "df['acc_y'] = data[4]\n",
    "df['acc_z'] = data[5]\n",
    "df['gesture'] = data[2]\n",
    "\n",
    "#remove invalid rows\n",
    "df.drop(df.loc[df['acc_x']==0].index, inplace=True)\n",
    "df.drop(df.loc[df['acc_y']==0].index, inplace=True)\n",
    "df.drop(df.loc[df['acc_z']==0].index, inplace=True)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert the lists into arrays\n",
    "acc_x = df['acc_x'].values\n",
    "acc_y = df['acc_y'].values\n",
    "acc_z = df['acc_z'].values\n",
    "\n",
    "# Combine all axes into a sequence of shape (timesteps, features)\n",
    "sequences = [np.array([x, y, z]).T for x, y, z in zip(acc_x, acc_y, acc_z)]\n",
    "\n",
    "# Pad sequences to the length of the longest sequence\n",
    "padded_sequences = pad_sequences(sequences, maxlen = 32, padding='post', dtype='float32')\n",
    "\n",
    "# Encode labels\n",
    "labels = df['gesture'].values\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "categorical_labels = to_categorical(encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "512cb331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA AUGMENTATION preprocessing\n",
    "\n",
    "#adding noise\n",
    "def add_noise(data, noise_level=0.05):\n",
    "    return (data + np.random.normal(0, noise_level, data.shape)).astype(np.float32)\n",
    "\n",
    "# Original data: `x_train` (accelerometer sequences), `y_train` (labels)\n",
    "\n",
    "padded_sequences = np.concatenate((padded_sequences, add_noise(padded_sequences)))\n",
    "categorical_labels = np.concatenate((categorical_labels, categorical_labels))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def scale_data(data, scaling_factor=0.1):\n",
    "    \"\"\"\n",
    "    Scale the data by a random factor.\n",
    "    Args:\n",
    "        data: Numpy array of shape (time_steps, 3).\n",
    "        scaling_factor: Max scaling factor variation.\n",
    "    Returns:\n",
    "        Scaled data.\n",
    "    \"\"\"\n",
    "    factor = 1 + np.random.uniform(-scaling_factor, scaling_factor)\n",
    "    return (data * factor).astype(np.float32)\n",
    "\n",
    "padded_sequences = np.concatenate((padded_sequences, scale_data(padded_sequences)))\n",
    "categorical_labels = np.concatenate((categorical_labels, categorical_labels))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1b22076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "    padded_sequences, categorical_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train, y_train, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f006b82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "214/214 [==============================] - 8s 7ms/step - loss: 2.7971 - accuracy: 0.1409 - val_loss: 2.4847 - val_accuracy: 0.4338\n",
      "Epoch 2/20\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 2.3103 - accuracy: 0.2724 - val_loss: 2.1028 - val_accuracy: 0.6925\n",
      "Epoch 3/20\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 2.0136 - accuracy: 0.3537 - val_loss: 1.7848 - val_accuracy: 0.7254\n",
      "Epoch 4/20\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 1.7924 - accuracy: 0.4253 - val_loss: 1.3885 - val_accuracy: 0.8180\n",
      "Epoch 5/20\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 1.6101 - accuracy: 0.4827 - val_loss: 1.1015 - val_accuracy: 0.8675\n",
      "Epoch 6/20\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 1.4647 - accuracy: 0.5295 - val_loss: 0.8291 - val_accuracy: 0.8829\n",
      "Epoch 7/20\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 1.3436 - accuracy: 0.5645 - val_loss: 0.7064 - val_accuracy: 0.8750\n",
      "Epoch 8/20\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 1.2772 - accuracy: 0.5832 - val_loss: 0.5685 - val_accuracy: 0.9123\n",
      "Epoch 9/20\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 1.1566 - accuracy: 0.6206 - val_loss: 0.5087 - val_accuracy: 0.8895\n",
      "Epoch 10/20\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 1.1061 - accuracy: 0.6320 - val_loss: 0.4351 - val_accuracy: 0.9026\n",
      "Epoch 11/20\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 1.0528 - accuracy: 0.6506 - val_loss: 0.4022 - val_accuracy: 0.9101\n",
      "Epoch 12/20\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 0.9929 - accuracy: 0.6651 - val_loss: 0.3421 - val_accuracy: 0.9368\n",
      "Epoch 13/20\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 0.9702 - accuracy: 0.6655 - val_loss: 0.3460 - val_accuracy: 0.9039\n",
      "Epoch 14/20\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 0.9384 - accuracy: 0.6781 - val_loss: 0.3159 - val_accuracy: 0.9206\n",
      "Epoch 15/20\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 0.9120 - accuracy: 0.6870 - val_loss: 0.2798 - val_accuracy: 0.9254\n",
      "Epoch 16/20\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 0.8909 - accuracy: 0.6920 - val_loss: 0.2722 - val_accuracy: 0.9346\n",
      "Epoch 17/20\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 0.8640 - accuracy: 0.7003 - val_loss: 0.2434 - val_accuracy: 0.9447\n",
      "Epoch 18/20\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 0.8400 - accuracy: 0.7057 - val_loss: 0.2300 - val_accuracy: 0.9561\n",
      "Epoch 19/20\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 0.8369 - accuracy: 0.7101 - val_loss: 0.2141 - val_accuracy: 0.9557\n",
      "Epoch 20/20\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 0.7937 - accuracy: 0.7213 - val_loss: 0.2152 - val_accuracy: 0.9425\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Train using model.fit\n",
    "\n",
    "# Train the model\n",
    "history = qat_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_validation, y_validation),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b9dcccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization aware training loss:  0.19982585310935974\n",
      "Quantization aware training accuracy:  0.9552631378173828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amroset/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the test set\n",
    "quant_loss, quant_acc = qat_model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Quantization aware training loss: ', quant_loss)\n",
    "print('Quantization aware training accuracy: ', quant_acc)\n",
    "qat_model.save('no_qkeras_qat_cnn_gesture_classification_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e435091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp1_esz8bj/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp1_esz8bj/assets\n",
      "/home/amroset/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-12-31 13:50:30.757241: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-12-31 13:50:30.757259: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-12-31 13:50:30.757369: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp1_esz8bj\n",
      "2024-12-31 13:50:30.760175: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-12-31 13:50:30.760187: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp1_esz8bj\n",
      "2024-12-31 13:50:30.768071: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-12-31 13:50:30.841941: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp1_esz8bj\n",
      "2024-12-31 13:50:30.862144: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 104771 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 12, Total Ops 48, % non-converted = 25.00 %\n",
      " * 12 ARITH ops\n",
      "\n",
      "- arith.constant:   12 occurrences  (f32: 6, i32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 3)\n",
      "  (uq_8: 2)\n",
      "  (f32: 4)\n",
      "  (uq_8: 2)\n",
      "  (uq_8: 1)\n",
      "  (f32: 3)\n",
      "  (i32: 1)\n",
      "  (uq_8: 4, uq_32: 4)\n",
      "  (uq_8: 4)\n",
      "  (uq_8: 2)\n",
      "  (i32: 1)\n",
      "  (uq_8: 1)\n",
      "  (i32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    }
   ],
   "source": [
    "# convert the QAT model to a fully quantized model using TFLite\n",
    "\n",
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(X_train).batch(1).take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(qat_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant_int8_qat = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfac8649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.uint8'>\n",
      "output:  <class 'numpy.uint8'>\n",
      "TFLite Model size with 8-bit quantization: 15 KB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant_int8_qat)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)\n",
    "# Save the quantized model to disk\n",
    "open(\"models/no_qkeras_gesture_qat_int8.tflite\", \"wb\").write(tflite_model_quant_int8_qat)\n",
    "\n",
    "# Show the model size for the 8-bit quantized TFLite model\n",
    "tflite_quant_in_kb = os.path.getsize('models/no_qkeras_gesture_qat_int8.tflite') / 1024\n",
    "print(\"TFLite Model size with 8-bit quantization: %d KB\" % tflite_quant_in_kb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3168877c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loaded_pruned \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241m.\u001b[39msaving\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/pruned_model_unstructured.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "loaded_pruned = keras.saving.load_model(\"models/pruned_model_unstructured.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "839a6b16",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m es \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m----> 3\u001b[0m         \u001b[43mkeras\u001b[49m\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, cooldown\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      4\u001b[0m                 \n\u001b[1;32m      5\u001b[0m     ]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Train and evaluate the pruned model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m pruned_model_unstructured\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m      8\u001b[0m                     X_train,\n\u001b[1;32m      9\u001b[0m                     y_train,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m                     callbacks \u001b[38;5;241m=\u001b[39m [es]\n\u001b[1;32m     13\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "es = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_delta=0.0001, mode='auto', cooldown=0, min_lr=0)\n",
    "                \n",
    "    ]\n",
    "# Train and evaluate the pruned model\n",
    "pruned_model_unstructured.fit(\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    epochs=10,\n",
    "                    validation_data=(X_validation, y_validation),\n",
    "                    callbacks = [es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b203fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
