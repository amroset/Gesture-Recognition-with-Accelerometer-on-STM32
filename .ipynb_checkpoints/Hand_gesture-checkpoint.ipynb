{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623dce53-fc82-4f45-888c-8dca4e1191c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.model_selection\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "from tensorflow import keras\n",
    "from itertools import chain\n",
    "import gc\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05a3976-6780-4e36-ac78-f854eee45bb3",
   "metadata": {},
   "source": [
    "###Dowload the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638fc8fa-225f-465e-809b-564ef1b811e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 100\n",
    "slide = 12\n",
    "\n",
    "train = pd.read_csv('dataset/train.csv', header = None, converters = {\n",
    "    3: ast.literal_eval,\n",
    "    4: ast.literal_eval,\n",
    "    5: ast.literal_eval\n",
    "}, skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa05f0ff-d762-42ce-a0cf-76cba231d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9782226-647e-4d0c-b713-a584f0d36655",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "df['acc_x'] = train[3]\n",
    "df['acc_y'] = train[4]\n",
    "df['acc_z'] = train[5]\n",
    "df['gesture'] = train[2]\n",
    "\n",
    "df.drop(df.loc[df['gesture']==0].index, inplace=True)\n",
    "df.drop(df.loc[df['acc_x']==0].index, inplace=True)\n",
    "df.drop(df.loc[df['acc_y']==0].index, inplace=True)\n",
    "df.drop(df.loc[df['acc_z']==0].index, inplace=True)\n",
    "\n",
    "# Reduce each list to its mean value\n",
    "df['acc_x'] = df['acc_x'].apply(lambda x: sum(x) / len(x) if isinstance(x, list) else x)\n",
    "df['acc_y'] = df['acc_y'].apply(lambda x: sum(x) / len(x) if isinstance(x, list) else x)\n",
    "df['acc_z'] = df['acc_z'].apply(lambda x: sum(x) / len(x) if isinstance(x, list) else x)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "X = df.loc[:,[\"acc_x\", \"acc_y\", \"acc_z\"]]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "label = sklearn.preprocessing.LabelEncoder()\n",
    "df['label'] = label.fit_transform(df['gesture'])\n",
    "y = df.loc[:,\"label\"]\n",
    "\n",
    "\n",
    "df = pd.DataFrame(X_scaled)\n",
    "df['label'] = y\n",
    "df.columns = ['acc_x', 'acc_y', 'acc_z', 'label']\n",
    "\n",
    "n_features = X_scaled.shape[1]\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c01a400-50ba-400f-9cdc-504f4f3028c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomWindowGenerator(keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, X, y, index_array=None, window_size=256, batch_size=64, slide=50, shuffle=True, pass_array=False):\n",
    "        \n",
    "        # X and y are lists of datasets e.g. if we have two datasets (X1, y1) and (X2, y2), X is [X1, X2] and y is [y1, y2]\n",
    "        \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.w = window_size\n",
    "        self.batch_size = batch_size\n",
    "        self.slide = slide\n",
    "        self.shuffle = shuffle\n",
    "        self.index_array= np.array(list(chain(*[zip(np.repeat(idx, len(x)), np.arange(0, (len(x)-window_size+1), slide)) for idx, x in enumerate(X)])) if pass_array==False else index_array)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.index_array)\n",
    "        #self.epoch=1\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.index_array)\n",
    "        gc.collect()\n",
    "        keras.backend.clear_session()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        X_d = []\n",
    "        y_d = []\n",
    "        \n",
    "        for n, i in self.index_array[index*self.batch_size:index*self.batch_size + self.batch_size]:\n",
    "            \n",
    "            X_d.append([self.X[n][i:i+self.w]])\n",
    "            y_d.append(scipy.stats.mode(self.y[n][i:i+self.w])[0])\n",
    "        \n",
    "        return np.vstack(X_d), np.vstack(y_d)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.index_array)//self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc3037c-a4c5-47aa-9e87-8e2b49bd1d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model(num_classes):\n",
    "\n",
    "    gc.collect()\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input((100,3)),\n",
    "        keras.layers.Reshape((10,10,3)),\n",
    "        keras.layers.Conv2D(filters=8, kernel_size = (5,5), padding = \"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.Conv2D(filters=8, kernel_size = (5,5), padding= \"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.MaxPool2D(pool_size = 2),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(64),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.Dense(num_classes, activation = 'softmax'),\n",
    "        ]) \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181e4259-4ced-4d9b-9245-38b00eceebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# training hyperparameters\n",
    "\n",
    "batch_size = 20 \n",
    "epochs = 100\n",
    "print(df.columns)\n",
    "X = df[[\"acc_x\", \"acc_y\", \"acc_z\"]].values.astype(np.float32)\n",
    "y = df[[\"label\"]].fillna(19).values.astype(np.float32)\n",
    "\n",
    "num_classes = len(np.unique(y))\n",
    "print(\"Number of classes: \", num_classes)\n",
    "\n",
    "one_hot_y = keras.utils.to_categorical(y, num_classes)\n",
    "\n",
    "kfold = sklearn.model_selection.StratifiedShuffleSplit(n_splits=5, test_size=0.2, train_size=0.8, random_state=1)\n",
    "\n",
    "fold = 1\n",
    "\n",
    "results_k = []\n",
    "results_tflite = []\n",
    "results_qk = []\n",
    "\n",
    "\n",
    "index_array = np.array(list(chain(*[zip(np.repeat(idx, len(x)), np.arange(0, (len(x)-window_size+1), slide)) for idx, x in enumerate([X])])))\n",
    "\n",
    "y_index_array = []\n",
    "for _, i in index_array:\n",
    "        y_index_array.append(scipy.stats.mode(y[i:i+window_size])[0])    \n",
    "\n",
    "\n",
    "train_index_array, test_index_array = sklearn.model_selection.train_test_split(index_array, test_size=0.2, random_state=42, shuffle=True, stratify=y_index_array)\n",
    "\n",
    "test_gen = CustomWindowGenerator([X], [one_hot_y], index_array=test_index_array, window_size=window_size, batch_size=batch_size, slide=slide, shuffle=True, pass_array=True)\n",
    "\n",
    "X_test_lite = []\n",
    "y_test_lite = []\n",
    "\n",
    "for _,i in test_index_array:\n",
    "        X_test_lite.append(X[i:i+window_size])\n",
    "        y_test_lite.append(scipy.stats.mode(y[i:i+window_size])[0])\n",
    "\n",
    "X_test_lite = np.asarray(X_test_lite, dtype=np.float32)\n",
    "y_test_lite = np.asarray(y_test_lite, dtype=np.int8)\n",
    "\n",
    "# K fold validation 5 steps\n",
    "\n",
    "for train_idx, val_idx in kfold.split(X = np.zeros(len(train_index_array)), y = y[train_index_array[:,1]]):\n",
    "        \n",
    "\n",
    "        train_gen = CustomWindowGenerator([X], [one_hot_y], index_array=train_index_array[train_idx], window_size=window_size, batch_size=batch_size, slide=slide, shuffle=True, pass_array=True)\n",
    "        val_gen = CustomWindowGenerator([X], [one_hot_y], index_array=train_index_array[val_idx], window_size=window_size, batch_size=batch_size, slide=slide, shuffle=True, pass_array=True)\n",
    "        \n",
    "        model = get_cnn_model(num_classes)\n",
    "\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics = ['accuracy'])\n",
    "        \n",
    "        print(\"K fold validation step:\",fold)\n",
    "\n",
    "        # model callbacks\n",
    "        earlyStopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='min')\n",
    "\n",
    "        keras_models_dir = \"cnn/keras_models/\"\n",
    "        os.makedirs(keras_models_dir, exist_ok=True)\n",
    "        mcp_path = keras_models_dir+'model_best_'+'k_fold_'+str(fold)+'.h5'\n",
    "        mcp_save = keras.callbacks.ModelCheckpoint(mcp_path, save_best_only=True, monitor='val_loss', mode='min')\n",
    "        \n",
    "        reduce_lr_loss = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, min_delta=0.0001, mode='auto', cooldown=0, min_lr=0)\n",
    "        \n",
    "        # model training\n",
    "        \n",
    "        model.fit(train_gen, validation_data=val_gen, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[earlyStopping, reduce_lr_loss, mcp_save])\n",
    "        \n",
    "        model = keras.models.load_model(mcp_path)\n",
    "\n",
    "        #evaluating the model on test data\n",
    "\n",
    "        result = model.evaluate(test_gen)\n",
    "        print(\"\\n\\n*****************************************keras model accuracy {} result: {}*****************************************\".format(fold, result[1]))\n",
    "        results_k.append(result[1])\n",
    "\n",
    "        fold+=1\n",
    "    \n",
    "results_k = np.asarray(results_k)\n",
    "os.makedirs(f\"./cnn/results\", exist_ok=True)\n",
    "np.save(f\"./cnn/results/results_keras.npy\", results_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bded298c-44fa-42fe-a7dc-e4947f403000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9d2759-886e-49d3-ba10-9a2308faffda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f5b604-f181-4e29-8eba-63303dc30ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
