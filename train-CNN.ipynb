{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe2ec573",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 14:42:35.435442: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-10 14:42:35.457295: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-10 14:42:35.457328: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-10 14:42:35.457922: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-10 14:42:35.462165: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-10 14:42:35.867919: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU, Dropout, BatchNormalization, Conv1D, MaxPooling1D, Flatten, Input, Reshape, Conv2D, ReLU, MaxPool2D, Masking\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import ast\n",
    "\n",
    "# Load and preprocess the data\n",
    "# Replace 'train.csv' with the actual path to your dataset\n",
    "data = pd.read_csv('dataset/train.csv', header = None, converters = {\n",
    "    3: ast.literal_eval,\n",
    "    4: ast.literal_eval,\n",
    "    5: ast.literal_eval\n",
    "}, skiprows = 1)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['acc_x'] = data[3]\n",
    "df['acc_y'] = data[4]\n",
    "df['acc_z'] = data[5]\n",
    "df['gesture'] = data[2]\n",
    "\n",
    "#remove invalid rows\n",
    "df.drop(df.loc[df['acc_x']==0].index, inplace=True)\n",
    "df.drop(df.loc[df['acc_y']==0].index, inplace=True)\n",
    "df.drop(df.loc[df['acc_z']==0].index, inplace=True)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert the lists into arrays\n",
    "acc_x = df['acc_x'].values\n",
    "acc_y = df['acc_y'].values\n",
    "acc_z = df['acc_z'].values\n",
    "\n",
    "# Combine all axes into a sequence of shape (timesteps, features)\n",
    "sequences = [np.array([x, y, z]).T for x, y, z in zip(acc_x, acc_y, acc_z)]\n",
    "\n",
    "# Pad sequences to the length of the longest sequence\n",
    "padded_sequences = pad_sequences(sequences, maxlen = 32, padding='post', dtype='float32')\n",
    "\n",
    "# Encode labels\n",
    "labels = df['gesture'].values\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "categorical_labels = to_categorical(encoded_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebaa9684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA AUGMENTATION preprocessing\n",
    "\n",
    "#adding noise\n",
    "def add_noise(data, noise_level=0.05):\n",
    "    return (data + np.random.normal(0, noise_level, data.shape)).astype(np.float32)\n",
    "\n",
    "# Original data: `x_train` (accelerometer sequences), `y_train` (labels)\n",
    "\n",
    "padded_sequences = np.concatenate((padded_sequences, add_noise(padded_sequences)))\n",
    "categorical_labels = np.concatenate((categorical_labels, categorical_labels))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def scale_data(data, scaling_factor=0.1):\n",
    "    \"\"\"\n",
    "    Scale the data by a random factor.\n",
    "    Args:\n",
    "        data: Numpy array of shape (time_steps, 3).\n",
    "        scaling_factor: Max scaling factor variation.\n",
    "    Returns:\n",
    "        Scaled data.\n",
    "    \"\"\"\n",
    "    factor = 1 + np.random.uniform(-scaling_factor, scaling_factor)\n",
    "    return (data * factor).astype(np.float32)\n",
    "\n",
    "padded_sequences = np.concatenate((padded_sequences, scale_data(padded_sequences)))\n",
    "categorical_labels = np.concatenate((categorical_labels, categorical_labels))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c22ed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "    padded_sequences, categorical_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train, y_train, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81763a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "214/214 [==============================] - 2s 4ms/step - loss: 2.7899 - accuracy: 0.1355 - val_loss: 2.5484 - val_accuracy: 0.3596\n",
      "Epoch 2/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.3422 - accuracy: 0.2794 - val_loss: 2.1593 - val_accuracy: 0.6018\n",
      "Epoch 3/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.0390 - accuracy: 0.3579 - val_loss: 1.7547 - val_accuracy: 0.7329\n",
      "Epoch 4/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1.8174 - accuracy: 0.4154 - val_loss: 1.3835 - val_accuracy: 0.7991\n",
      "Epoch 5/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1.6085 - accuracy: 0.4936 - val_loss: 1.0047 - val_accuracy: 0.8623\n",
      "Epoch 6/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1.4452 - accuracy: 0.5417 - val_loss: 0.7786 - val_accuracy: 0.8803\n",
      "Epoch 7/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1.3014 - accuracy: 0.5794 - val_loss: 0.6317 - val_accuracy: 0.8877\n",
      "Epoch 8/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1.2278 - accuracy: 0.6143 - val_loss: 0.5252 - val_accuracy: 0.8838\n",
      "Epoch 9/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1.1242 - accuracy: 0.6273 - val_loss: 0.4591 - val_accuracy: 0.9127\n",
      "Epoch 10/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1.0873 - accuracy: 0.6439 - val_loss: 0.3901 - val_accuracy: 0.9294\n",
      "Epoch 11/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1.0095 - accuracy: 0.6654 - val_loss: 0.3535 - val_accuracy: 0.9382\n",
      "Epoch 12/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.9866 - accuracy: 0.6732 - val_loss: 0.3391 - val_accuracy: 0.9307\n",
      "Epoch 13/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.9566 - accuracy: 0.6773 - val_loss: 0.3035 - val_accuracy: 0.9425\n",
      "Epoch 14/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.8955 - accuracy: 0.7023 - val_loss: 0.2764 - val_accuracy: 0.9412\n",
      "Epoch 15/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.8883 - accuracy: 0.7098 - val_loss: 0.2571 - val_accuracy: 0.9531\n",
      "Epoch 16/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.8622 - accuracy: 0.7072 - val_loss: 0.2450 - val_accuracy: 0.9575\n",
      "Epoch 17/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.8159 - accuracy: 0.7232 - val_loss: 0.2314 - val_accuracy: 0.9509\n",
      "Epoch 18/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.7985 - accuracy: 0.7227 - val_loss: 0.2251 - val_accuracy: 0.9539\n",
      "Epoch 19/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.8253 - accuracy: 0.7168 - val_loss: 0.2061 - val_accuracy: 0.9561\n",
      "Epoch 20/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.7662 - accuracy: 0.7430 - val_loss: 0.1931 - val_accuracy: 0.9623\n",
      "Epoch 21/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.7291 - accuracy: 0.7518 - val_loss: 0.1803 - val_accuracy: 0.9623\n",
      "Epoch 22/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.7380 - accuracy: 0.7499 - val_loss: 0.1642 - val_accuracy: 0.9636\n",
      "Epoch 23/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.7309 - accuracy: 0.7465 - val_loss: 0.1654 - val_accuracy: 0.9658\n",
      "Epoch 24/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.7286 - accuracy: 0.7510 - val_loss: 0.1556 - val_accuracy: 0.9667\n",
      "Epoch 25/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.7074 - accuracy: 0.7544 - val_loss: 0.1551 - val_accuracy: 0.9618\n",
      "Epoch 26/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.6879 - accuracy: 0.7645 - val_loss: 0.1403 - val_accuracy: 0.9697\n",
      "Epoch 27/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.6615 - accuracy: 0.7775 - val_loss: 0.1418 - val_accuracy: 0.9680\n",
      "Epoch 28/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.6579 - accuracy: 0.7753 - val_loss: 0.1364 - val_accuracy: 0.9671\n",
      "Epoch 29/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.6650 - accuracy: 0.7703 - val_loss: 0.1241 - val_accuracy: 0.9737\n",
      "Epoch 30/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.6425 - accuracy: 0.7823 - val_loss: 0.1165 - val_accuracy: 0.9750\n",
      "Epoch 31/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.6413 - accuracy: 0.7770 - val_loss: 0.1200 - val_accuracy: 0.9715\n",
      "Epoch 32/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.6310 - accuracy: 0.7794 - val_loss: 0.1116 - val_accuracy: 0.9724\n",
      "Epoch 33/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.6163 - accuracy: 0.7838 - val_loss: 0.1152 - val_accuracy: 0.9754\n",
      "Epoch 34/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.5987 - accuracy: 0.7953 - val_loss: 0.1060 - val_accuracy: 0.9768\n",
      "Epoch 35/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.6272 - accuracy: 0.7813 - val_loss: 0.1026 - val_accuracy: 0.9732\n",
      "Epoch 36/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.5972 - accuracy: 0.7908 - val_loss: 0.0944 - val_accuracy: 0.9768\n",
      "Epoch 37/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.5921 - accuracy: 0.7955 - val_loss: 0.0937 - val_accuracy: 0.9811\n",
      "Epoch 38/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.5861 - accuracy: 0.7996 - val_loss: 0.0885 - val_accuracy: 0.9820\n",
      "Epoch 39/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.5970 - accuracy: 0.7934 - val_loss: 0.0893 - val_accuracy: 0.9798\n",
      "Epoch 40/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.5676 - accuracy: 0.8048 - val_loss: 0.0915 - val_accuracy: 0.9807\n",
      "Epoch 41/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.5684 - accuracy: 0.7984 - val_loss: 0.0853 - val_accuracy: 0.9794\n",
      "Epoch 42/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.5833 - accuracy: 0.7966 - val_loss: 0.0877 - val_accuracy: 0.9776\n",
      "Epoch 43/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.5617 - accuracy: 0.8067 - val_loss: 0.0850 - val_accuracy: 0.9807\n",
      "Epoch 44/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.5574 - accuracy: 0.7993 - val_loss: 0.0789 - val_accuracy: 0.9825\n",
      "Epoch 45/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.5464 - accuracy: 0.8129 - val_loss: 0.0809 - val_accuracy: 0.9811\n",
      "Epoch 46/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.5396 - accuracy: 0.8124 - val_loss: 0.0729 - val_accuracy: 0.9846\n",
      "Epoch 47/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.5274 - accuracy: 0.8137 - val_loss: 0.0787 - val_accuracy: 0.9825\n",
      "Epoch 48/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.5262 - accuracy: 0.8158 - val_loss: 0.0747 - val_accuracy: 0.9816\n",
      "Epoch 49/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.5419 - accuracy: 0.8154 - val_loss: 0.0718 - val_accuracy: 0.9838\n",
      "Epoch 50/50\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 0.5162 - accuracy: 0.8202 - val_loss: 0.0716 - val_accuracy: 0.9829\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.0610 - accuracy: 0.9890\n",
      "Test Loss: 0.060958970338106155, Test Accuracy: 0.9890350699424744\n",
      "72/72 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amroset/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Neural network model\n",
    "model = Sequential([\n",
    "    Input(shape=(32, 3)),\n",
    "    # Mask padding values\n",
    "    #Masking(mask_value=0.0, input_shape=(None, 3)),\n",
    "    Reshape((8,4,3)),\n",
    "    Conv2D(filters=32, kernel_size = (3,3), padding = \"same\"),\n",
    "    Dropout(0.3),\n",
    "    BatchNormalization(),\n",
    "    ReLU(),\n",
    "    Conv2D(filters=16, kernel_size = (3,3), padding= \"same\"),\n",
    "    Dropout(0.4),\n",
    "    BatchNormalization(),\n",
    "    ReLU(),\n",
    "    MaxPool2D(pool_size = 2),\n",
    "    \n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(16),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    ReLU(),\n",
    "\n",
    "    Dense(len(label_encoder.classes_), activation = 'softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_validation, y_validation),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Save the model\n",
    "model.save('cnn_gesture_classification_model.h5')\n",
    "\n",
    "# Decode predicted labels for interpretability\n",
    "predicted_classes = label_encoder.inverse_transform(np.argmax(model.predict(X_test), axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d25fb062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 8, 4, 3)           0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 8, 4, 32)          896       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 8, 4, 32)          0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 8, 4, 32)          128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 8, 4, 32)          0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 8, 4, 16)          4624      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 4, 16)          0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 8, 4, 16)          64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 8, 4, 16)          0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 4, 2, 16)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                2064      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 16)                64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                340       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8180 (31.95 KB)\n",
      "Trainable params: 8052 (31.45 KB)\n",
      "Non-trainable params: 128 (512.00 Byte)\n",
      "_________________________________________________________________\n",
      "[[[-1.25576019e+00  5.40589333e-01 -1.17370591e-01]\n",
      "  [-1.37073982e+00  6.13141954e-01  8.21594968e-02]\n",
      "  [-1.98396564e+00 -1.12385623e-01  6.80747569e-01]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[-1.44861257e+00  5.53108096e-01 -8.15017343e-01]\n",
      "  [-1.54418087e+00  6.37405157e-01 -8.77711058e-01]\n",
      "  [-2.14944601e+00  2.72117406e-01 -1.88080564e-01]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 1.37199759e+00 -1.89166951e+00  8.73655081e-01]\n",
      "  [ 1.46414673e+00 -1.80867112e+00  8.73655081e-01]\n",
      "  [ 1.40271401e+00 -1.64267445e+00  8.43000531e-01]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-3.25337887e-01 -4.61486965e-01 -1.84492335e-01]\n",
      "  [-3.38793367e-01 -3.75908256e-01 -1.88744724e-01]\n",
      "  [-7.09254593e-02  1.56494766e-01  5.49553871e-01]\n",
      "  ...\n",
      "  [ 1.16957845e-02  3.73761468e-02 -4.94581275e-02]\n",
      "  [-4.49289680e-02  8.68230835e-02 -4.82915156e-02]\n",
      "  [-4.05769236e-03  7.37148672e-02 -8.37356895e-02]]\n",
      "\n",
      " [[ 9.85915661e-01 -9.21010971e-01 -1.24336168e-01]\n",
      "  [ 1.25023222e+00 -9.40741241e-01 -1.35337666e-01]\n",
      "  [ 8.86678040e-01 -3.73569846e-01  1.20343888e+00]\n",
      "  ...\n",
      "  [-3.21288453e-03 -1.17389746e-02  4.94885892e-02]\n",
      "  [ 4.39061299e-02  1.80605724e-02 -5.36326952e-02]\n",
      "  [ 6.97950542e-04  2.73894370e-02  3.02866306e-02]]\n",
      "\n",
      " [[ 7.99979031e-01 -8.83685946e-01 -4.41892207e-01]\n",
      "  [ 9.99387503e-01 -8.13543141e-01 -5.22205412e-01]\n",
      "  [ 8.11104476e-01 -8.41698289e-01 -5.61824977e-01]\n",
      "  ...\n",
      "  [-4.88410443e-02 -1.32110223e-01  8.48595705e-03]\n",
      "  [ 7.68570825e-02  6.24981360e-04 -2.83400659e-02]\n",
      "  [-1.24811353e-02 -6.57499805e-02 -8.31105839e-03]]]\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "Predictions saved to test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "#Inference\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('models/cnn_gesture_classification_model.h5')\n",
    "model.summary()\n",
    "\n",
    "print(padded_sequences)\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv('dataset/test.csv', header=None, converters={\n",
    "    2: ast.literal_eval,\n",
    "    3: ast.literal_eval,\n",
    "    4: ast.literal_eval\n",
    "}, skiprows=1)\n",
    "\n",
    "# Preprocess the test data\n",
    "df_test = pd.DataFrame()\n",
    "df_test['acc_x'] = test_data[2]\n",
    "df_test['acc_y'] = test_data[3]\n",
    "df_test['acc_z'] = test_data[4]\n",
    "\n",
    "# Ensure all data is consistent (dropping invalid or zero entries)\n",
    "df_test.drop(df_test.loc[df_test['acc_x'] == 0].index, inplace=True)\n",
    "df_test.drop(df_test.loc[df_test['acc_y'] == 0].index, inplace=True)\n",
    "df_test.drop(df_test.loc[df_test['acc_z'] == 0].index, inplace=True)\n",
    "\n",
    "df_test = df_test.dropna()\n",
    "\n",
    "# Extract accelerometer data (acc_x, acc_y, acc_z) for the test set\n",
    "acc_x = df_test['acc_x'].values\n",
    "acc_y = df_test['acc_y'].values\n",
    "acc_z = df_test['acc_z'].values\n",
    "\n",
    "test_sequences = [np.array([x, y, z]).T for x, y, z in zip(acc_x, acc_y, acc_z)]\n",
    "\n",
    "# Pad sequences to the length of the longest sequence\n",
    "padded_test_sequences = pad_sequences(test_sequences, padding='post', dtype='float32')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(padded_test_sequences)\n",
    "\n",
    "# Decode predictions to gesture classes\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# If you used a LabelEncoder for training, decode the classes\n",
    "# Replace 'label_encoder' with your encoder used during training\n",
    "gesture_labels = label_encoder.inverse_transform(predicted_classes)\n",
    "\n",
    "df_out = pd.DataFrame()\n",
    "df_out['id'] = test_data[0]\n",
    "df_out['gesture'] = gesture_labels\n",
    "\n",
    "\n",
    "# Save the results\n",
    "df_out.to_csv('cnn_test_predictions.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to test_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d07945f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmprk3nz1yx/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmprk3nz1yx/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with full integer quantization saved as gesture_classification_model_integer.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amroset/anaconda3/envs/microcontrollers/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2025-01-04 15:08:48.379928: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2025-01-04 15:08:48.379944: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2025-01-04 15:08:48.380125: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmprk3nz1yx\n",
      "2025-01-04 15:08:48.381758: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-01-04 15:08:48.381787: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmprk3nz1yx\n",
      "2025-01-04 15:08:48.385305: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2025-01-04 15:08:48.386435: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2025-01-04 15:08:48.433630: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmprk3nz1yx\n",
      "2025-01-04 15:08:48.445656: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 65529 microseconds.\n",
      "2025-01-04 15:08:48.460971: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 14, Total Ops 28, % non-converted = 50.00 %\n",
      " * 14 ARITH ops\n",
      "\n",
      "- arith.constant:   14 occurrences  (f32: 8, i32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 2)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (i32: 1)\n",
      "  (f32: 2)\n",
      "  (i32: 1)\n",
      "  (f32: 1)\n",
      "  (i32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(padded_sequences).batch(1).take(32):\n",
    "    yield [input_value]\n",
    "\n",
    "# Ensure input shape is fixed\n",
    "model.build(input_shape=(None, 32, 3))  # Example: Fixed length 32 timesteps, 3 features\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# Apply integer quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]  # Ensure compatibility\n",
    "converter.inference_input_type = tf.uint8  # Optional: Set input type\n",
    "converter.inference_output_type = tf.uint8  # Optional: Set output type\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model\n",
    "with open('cnn_gesture_classification_model_integer.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Model with full integer quantization saved as gesture_classification_model_integer.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94fc5796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp9r8qxzuc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp9r8qxzuc/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDF5 Model size without quantization: 442 KB\n",
      "TFLite Model size without quantization: 35 KB\n",
      "\n",
      "Reduction in file size by a factor of 12.375984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 15:08:51.855770: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2025-01-04 15:08:51.855786: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2025-01-04 15:08:51.855891: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp9r8qxzuc\n",
      "2025-01-04 15:08:51.857569: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-01-04 15:08:51.857587: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp9r8qxzuc\n",
      "2025-01-04 15:08:51.861636: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2025-01-04 15:08:51.904751: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp9r8qxzuc\n",
      "2025-01-04 15:08:51.916893: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 61001 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 14, Total Ops 28, % non-converted = 50.00 %\n",
      " * 14 ARITH ops\n",
      "\n",
      "- arith.constant:   14 occurrences  (f32: 8, i32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 2)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (i32: 1)\n",
      "  (f32: 2)\n",
      "  (i32: 1)\n",
      "  (f32: 1)\n",
      "  (i32: 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Convert the model to TFLite without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "fp_tflite_model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(\"cnn_model_f32.tflite\", \"wb\").write(fp_tflite_model)\n",
    "\n",
    "# Show the model size for the non-quantized HDF5 model\n",
    "fp_h5_in_kb = os.path.getsize('models/gesture_classification_model.h5') / 1024\n",
    "print(\"HDF5 Model size without quantization: %d KB\" % fp_h5_in_kb)\n",
    "\n",
    "# Show the model size for the non-quantized TFLite model\n",
    "fp_tflite_in_kb = os.path.getsize('models/cnn_model_f32.tflite') / 1024\n",
    "print(\"TFLite Model size without quantization: %d KB\" % fp_tflite_in_kb)\n",
    "\n",
    "# Determine the reduction in model size\n",
    "print(\"\\nReduction in file size by a factor of %f\" % (fp_h5_in_kb / fp_tflite_in_kb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90af0a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.uint8'>\n",
      "output:  <class 'numpy.uint8'>\n",
      "TFLite Model size with 8-bit quantization: 14 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "WARNING: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors (tensor#19 is a dynamic-sized tensor).\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)\n",
    "\n",
    "# Show the model size for the 8-bit quantized TFLite model\n",
    "tflite_quant_in_kb = os.path.getsize('models/cnn_gesture_classification_model_integer.tflite') / 1024\n",
    "print(\"TFLite Model size with 8-bit quantization: %d KB\" % tflite_quant_in_kb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1ff3df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Helper function to run inference on a TFLite model\n",
    "\n",
    "test_sequence_indices = range(X_test.shape[0])\n",
    "\n",
    "print(y_test)\n",
    "\n",
    "def run_tflite_model(tflite_file, test_image_indices):\n",
    "  global X_test\n",
    "\n",
    "  # Initialize the interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  predictions = []\n",
    "  for i, test_sequence_index in enumerate(test_sequence_indices):\n",
    "    test_sequence = X_test[test_sequence_index]\n",
    "    test_label = y_test[test_sequence_index]\n",
    "\n",
    "    if (test_sequence_index % 100 == 0):\n",
    "      print(\"Evaluated on %d sequences.\" % test_sequence_index)\n",
    "\n",
    "    # Check if the input type is quantized, then rescale input data to uint8\n",
    "    if input_details['dtype'] == np.uint8:\n",
    "      input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "      test_sequence = test_sequence / input_scale + input_zero_point\n",
    "\n",
    "    test_sequence = np.expand_dims(test_sequence, axis=0).astype(input_details[\"dtype\"])\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_sequence)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "    predictions.append(np.argmax(output, axis=-1))\n",
    "\n",
    "  return predictions\n",
    "\n",
    "\n",
    "# Helper function to evaluate a TFLite model on all images\n",
    "def evaluate_model(tflite_file, model_type):\n",
    "  global X_test\n",
    "  global y_test\n",
    "\n",
    "  test_sequence_indices = range(X_train.shape[0])\n",
    "  predictions = run_tflite_model(tflite_file, test_sequence_indices)\n",
    "    \n",
    "  labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "  accuracy = (np.sum(labels == predictions) * 100) / len(X_test)\n",
    "\n",
    "  print('%s model accuracy is %.4f%% (Number of test samples=%d)' % (\n",
    "      model_type, accuracy, len(X_test)))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60907cd0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 sequences.\n",
      "Evaluated on 100 sequences.\n",
      "Evaluated on 200 sequences.\n",
      "Evaluated on 300 sequences.\n",
      "Evaluated on 400 sequences.\n",
      "Evaluated on 500 sequences.\n",
      "Evaluated on 600 sequences.\n",
      "Evaluated on 700 sequences.\n",
      "Evaluated on 800 sequences.\n",
      "Evaluated on 900 sequences.\n",
      "Evaluated on 1000 sequences.\n",
      "Evaluated on 1100 sequences.\n",
      "Evaluated on 1200 sequences.\n",
      "Evaluated on 1300 sequences.\n",
      "Evaluated on 1400 sequences.\n",
      "Evaluated on 1500 sequences.\n",
      "Evaluated on 1600 sequences.\n",
      "Evaluated on 1700 sequences.\n",
      "Evaluated on 1800 sequences.\n",
      "Evaluated on 1900 sequences.\n",
      "Evaluated on 2000 sequences.\n",
      "Evaluated on 2100 sequences.\n",
      "Evaluated on 2200 sequences.\n",
      "Full Post-Quantized INT8 model accuracy is 98.0702% (Number of test samples=2280)\n",
      "0.026128482073545456\n",
      "119\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "# this might take a few minutes (~ 1- 2 minutes)\n",
    "# if it takes longer than that, I suggest to \n",
    "# restart the runtime and try again\n",
    "# if the issue still persists, restart your computer\n",
    "tflite_model_quant_int8_file = pathlib.Path('models/cnn_gesture_classification_model_integer.tflite')\n",
    "tflite_model_quant_int8_model_type = \"Full Post-Quantized INT8\"\n",
    "\n",
    "evaluate_model(tflite_model_quant_int8_file, tflite_model_quant_int8_model_type)\n",
    "\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "\n",
    "print(input_scale)\n",
    "print(input_zero_point)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f5cb06e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 sequences.\n",
      "Evaluated on 100 sequences.\n",
      "Evaluated on 200 sequences.\n",
      "Evaluated on 300 sequences.\n",
      "Evaluated on 400 sequences.\n",
      "Evaluated on 500 sequences.\n",
      "Evaluated on 600 sequences.\n",
      "Evaluated on 700 sequences.\n",
      "Evaluated on 800 sequences.\n",
      "Evaluated on 900 sequences.\n",
      "Evaluated on 1000 sequences.\n",
      "Evaluated on 1100 sequences.\n",
      "Evaluated on 1200 sequences.\n",
      "Evaluated on 1300 sequences.\n",
      "Evaluated on 1400 sequences.\n",
      "Evaluated on 1500 sequences.\n",
      "Evaluated on 1600 sequences.\n",
      "Evaluated on 1700 sequences.\n",
      "Evaluated on 1800 sequences.\n",
      "Evaluated on 1900 sequences.\n",
      "Evaluated on 2000 sequences.\n",
      "Evaluated on 2100 sequences.\n",
      "Evaluated on 2200 sequences.\n",
      "Full-precision model accuracy is 98.9035% (Number of test samples=2280)\n",
      "Quantized model accuracy is 96.1404% (Number of test samples=2280)\n"
     ]
    }
   ],
   "source": [
    "# we plot also the confusion matrix of the quantized model\n",
    "tflite_model_quant_int8_pred = run_tflite_model(tflite_model_quant_int8_file, range(y_test.shape[0]))\n",
    "\n",
    "# compute the accuracy of the quantized model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "full_int8_accuracy = accuracy_score(labels, tflite_model_quant_int8_pred)\n",
    "print(\"Full-precision model accuracy is %.4f%% (Number of test samples=%d)\" % (test_accuracy * 100, len(y_test)))\n",
    "print(\"Quantized model accuracy is %.4f%% (Number of test samples=%d)\" % (full_int8_accuracy * 100, len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02a86b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Convert some hex value into an array for C programming\n",
    "def hex_to_c_array(hex_data, var_name):\n",
    "\n",
    "    c_str = ''\n",
    "\n",
    "    # Create header guard\n",
    "    c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n",
    "    c_str += '#define ' + var_name.upper() + '_H\\n\\n'\n",
    "\n",
    "    # Add array length at top of file\n",
    "    c_str += '\\nstatic const unsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n",
    "\n",
    "    # Declare C variable\n",
    "    c_str += 'static const unsigned char ' + var_name + '[] = {'\n",
    "    hex_array = []\n",
    "    for i, val in enumerate(hex_data) :\n",
    "\n",
    "        # Construct string from hex\n",
    "        hex_str = format(val, '#04x')\n",
    "\n",
    "        # Add formatting so each line stays within 80 characters\n",
    "        if (i + 1) < len(hex_data):\n",
    "            hex_str += ','\n",
    "        if (i + 1) % 12 == 0:\n",
    "            hex_str += '\\n '\n",
    "        hex_array.append(hex_str)\n",
    "\n",
    "    # Add closing brace\n",
    "    c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n",
    "\n",
    "    # Close out header guard\n",
    "    c_str += '#endif //' + var_name.upper() + '_H'\n",
    "\n",
    "    return c_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0392b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_model_name = 'q8_cnn'\n",
    "# check if dir 'cfiles' exists, if not create it\n",
    "if not os.path.exists('cfiles'):\n",
    "    os.makedirs('cfiles')\n",
    "# Write TFLite model to a C source (or header) file\n",
    "with open('cfiles/' + c_model_name + '.h', 'w') as file:\n",
    "    file.write(hex_to_c_array(tflite_model, c_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4445fc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image data location:  /home/amroset/Machine Learning on Microcontrollers/Project/x_test_gestures.npy\n",
      "Test labels location:  /home/amroset/Machine Learning on Microcontrollers/Project/y_test_gestures.npy\n"
     ]
    }
   ],
   "source": [
    "input_details = interpreter.get_input_details()[0]\n",
    "input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "\n",
    "# save the test data as numpy arrays\n",
    "np.save('x_test_gestures.npy', (X_test / input_scale + input_zero_point).astype(np.uint8))\n",
    "np.save('y_test_gestures.npy', (y_test.astype(np.uint8)))\n",
    "\n",
    "# print the location of the files\n",
    "print('Test image data location: ', os.path.abspath('x_test_gestures.npy'))\n",
    "print('Test labels location: ', os.path.abspath('y_test_gestures.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "348ac827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 sequences.\n",
      "Evaluated on 100 sequences.\n",
      "Evaluated on 200 sequences.\n",
      "Evaluated on 300 sequences.\n",
      "Evaluated on 400 sequences.\n",
      "Evaluated on 500 sequences.\n",
      "Evaluated on 600 sequences.\n",
      "Evaluated on 700 sequences.\n",
      "Evaluated on 800 sequences.\n",
      "Evaluated on 900 sequences.\n",
      "Evaluated on 1000 sequences.\n",
      "Evaluated on 1100 sequences.\n",
      "Evaluated on 1200 sequences.\n",
      "Evaluated on 1300 sequences.\n",
      "Evaluated on 1400 sequences.\n",
      "Evaluated on 1500 sequences.\n",
      "Evaluated on 1600 sequences.\n",
      "Evaluated on 1700 sequences.\n",
      "Evaluated on 1800 sequences.\n",
      "Evaluated on 1900 sequences.\n",
      "Evaluated on 2000 sequences.\n",
      "Evaluated on 2100 sequences.\n",
      "Evaluated on 2200 sequences.\n",
      "Full QAT INT8 model accuracy is 97.8070% (Number of test samples=2280)\n",
      "Full-precision model accuracy is 96.8860% (Number of test samples=6840)\n"
     ]
    }
   ],
   "source": [
    "# this might take a few minutes (~ 1- 2 minutes)\n",
    "# if it takes longer than that, I suggest to \n",
    "# restart the runtime and try again\n",
    "# if the issue still persists, restart your computer\n",
    "tflite_model_quant_int8_qat_file = pathlib.Path('models/no_qkeras_gesture_qat_int8.tflite')\n",
    "tflite_model_quant_int8_qat_type = \"Full QAT INT8\"\n",
    "\n",
    "evaluate_model(tflite_model_quant_int8_qat_file, tflite_model_quant_int8_qat_type)\n",
    "print(\"Full-precision model accuracy is %.4f%% (Number of test samples=%d)\" % (test_accuracy * 100, len(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "09faa18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 sequences.\n",
      "Evaluated on 100 sequences.\n",
      "Evaluated on 200 sequences.\n",
      "Evaluated on 300 sequences.\n",
      "Evaluated on 400 sequences.\n",
      "Evaluated on 500 sequences.\n",
      "Evaluated on 600 sequences.\n",
      "Evaluated on 700 sequences.\n",
      "Evaluated on 800 sequences.\n",
      "Evaluated on 900 sequences.\n",
      "Evaluated on 1000 sequences.\n",
      "Evaluated on 1100 sequences.\n",
      "Evaluated on 1200 sequences.\n",
      "Evaluated on 1300 sequences.\n",
      "Evaluated on 1400 sequences.\n",
      "Evaluated on 1500 sequences.\n",
      "Evaluated on 1600 sequences.\n",
      "Evaluated on 1700 sequences.\n",
      "Evaluated on 1800 sequences.\n",
      "Evaluated on 1900 sequences.\n",
      "Evaluated on 2000 sequences.\n",
      "Evaluated on 2100 sequences.\n",
      "Evaluated on 2200 sequences.\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the test set\n",
    "tflite_model_quant_int8_qat_file = \"models/no_qkeras_gesture_qat_int8.tflite\"\n",
    "tflite_model_quant_int8_qat_model_type = \"Quantized aware training model\"\n",
    "tflite_model_quant_int8_qat_pred = run_tflite_model(tflite_model_quant_int8_qat_file, range(X_train.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "715b57f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full QAT INT8 accuracy is 97.8070% (Number of test samples=2280)\n",
      "Full-precision model accuracy is 96.8860% (Number of test samples=2280)\n"
     ]
    }
   ],
   "source": [
    "# compute the accuracy of the model\n",
    "full_qat_int8_accuracy = accuracy_score(labels, tflite_model_quant_int8_qat_pred)\n",
    "print('Full QAT INT8 accuracy is %.4f%% (Number of test samples=%d)' % (full_qat_int8_accuracy * 100, len(y_test)))\n",
    "print('Full-precision model accuracy is %.4f%% (Number of test samples=%d)' % (test_accuracy * 100, len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8660a71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
